# -*- coding: utf-8 -*-
"""NBA Fair Value Calculator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TljzKWMSHveej46ulBGnfJqGwweo3GGp

> **Overview of NBA Fair Value Calculator (FVC)**



*   Proportion of Luxury Tax and/or 1st Apron occuppied by new contracts' avg. annual value (AAV) vs. "Production" (before & after signing)
*   Other considerations: playoff performance, team win% post signing, attendance (i.e. revenue)

# Sourcing & Pre-Processing Data

## League Salary Cap Info
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

url = 'https://basketball.realgm.com/nba/info/salary_cap'

# Fetch the page content
response = requests.get(url)
html_content = response.content

# Parse the HTML with BeautifulSoup
soup = BeautifulSoup(html_content, 'html.parser')

# Initialize lists to store the data
seasons = []
salary_caps = []
luxury_taxes = []
first_aprons = []
second_aprons = []

# Select all rows in the table body
rows = soup.find_all('tr')

for row in rows:
    cols = row.find_all('td')
    # Ensure the row contains at least the number of columns we are interested in
    if len(cols) >= 7:
        season = cols[2].text.strip()       # The 3rd <td> element corresponds to 'Season'
        salary_cap = cols[3].text.strip()   # The 4th <td> element corresponds to 'Salary Cap'
        luxury_tax = cols[4].text.strip()   # The 5th <td> element corresponds to 'Luxury Tax'
        first_apron = cols[5].text.strip()  # The 6th <td> element corresponds to '1st Apron'
        second_apron = cols[6].text.strip() # The 7th <td> element corresponds to '2nd Apron'

        # Filter out rows where 'Season' is formatted differently or data is misaligned
        if season and season != '-' and '$' in salary_cap:
            # Append the extracted data to the lists
            seasons.append(season)
            salary_caps.append(salary_cap)
            luxury_taxes.append(luxury_tax)
            first_aprons.append(first_apron)
            second_aprons.append(second_apron)

# Create a DataFrame from the lists
NBA_salary_cap = pd.DataFrame({
    'Season': seasons,
    'Salary Cap': salary_caps,
    'Luxury Tax': luxury_taxes,
    '1st Apron': first_aprons,
    '2nd Apron': second_aprons
})

# Display the DataFrame
NBA_salary_cap.head()

"""### Visual"""

import plotly.express as px
import requests
from bs4 import BeautifulSoup
import pandas as pd

# Convert necessary columns to numeric (remove $, commas)
NBA_salary_cap['Salary Cap'] = NBA_salary_cap['Salary Cap'].replace('[\$,]', '', regex=True).astype(int)
NBA_salary_cap['Luxury Tax'] = NBA_salary_cap['Luxury Tax'].replace('[\$,]', '', regex=True).replace('N/A', '0').astype(int)
NBA_salary_cap['1st Apron'] = NBA_salary_cap['1st Apron'].replace('[\$,]', '', regex=True).replace('N/A', '0').astype(int)

# Set the order of the DataFrame to have the oldest season first
NBA_salary_cap_increasing = NBA_salary_cap.iloc[::-1]

# Create the line plot
fig = px.line(NBA_salary_cap_increasing, x='Season', y=['Salary Cap', 'Luxury Tax', '1st Apron'],
              title='NBA Salary Cap, Luxury Tax, and 1st Apron Increase Per Season',
              labels={'Season': 'Season', 'value': 'Amount ($)', 'variable': 'Category'})

# Customize layout
fig.update_layout(
    xaxis_title='Season',
    yaxis_title='Amount ($)',
    xaxis_tickangle=-45,
    xaxis=dict(
        tickmode='array',
        tickvals=[NBA_salary_cap_increasing['Season'][i] for i in range(0, len(NBA_salary_cap_increasing), 4)]
    ),
    margin=dict(l=40, r=40, t=40, b=80)
)

fig.show()

"""## Player Contracts

### Web-Scrapping
"""

# # Contracts signed in 2020
# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# url = 'https://www.spotrac.com/nba/contracts/_/year/2020/sort/value'

# # Fetch page content
# response = requests.get(url)
# html_content = response.content

# # Parse HTML with BeautifulSoup
# soup = BeautifulSoup(html_content, 'html.parser')

# # Initialize lists to hold data
# players = []
# positions = []
# ages = []
# starts = []
# ends = []
# years = []
# values = []
# aavs = []

# # Find all rows in the table
# rows = soup.find_all('tr')

# # Iterate over each row to extract data
# for row in rows:
#     cols = row.find_all('td')
#     if len(cols) > 1:  # To ensure we skip any non-relevant rows
#         player = cols[1].text.strip()
#         position = cols[2].text.strip()
#         age = cols[4].text.strip()
#         start = cols[5].text.strip()
#         end = cols[6].text.strip()
#         year_length = cols[7].text.strip()
#         value = cols[8].text.strip()
#         aav = cols[9].text.strip()

#         # Append data to lists
#         players.append(player)
#         positions.append(position)
#         ages.append(age)
#         starts.append(start)
#         ends.append(end)
#         years.append(year_length)
#         values.append(value)
#         aavs.append(aav)

# # Create a DataFrame from the lists
# NBA_contracts_2020 = pd.DataFrame({
#     'Player': players,
#     'POS': positions,
#     'Age at Signing': ages,
#     'Start': starts,
#     'End': ends,
#     'YRS': years,
#     'Value': values,
#     'AAV': aavs
# })

# # Display the DataFrame
# NBA_contracts_2020.head()

# # Contracts signed in 2021
# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# url = 'https://www.spotrac.com/nba/contracts/_/year/2021/sort/value'

# # Fetch page content
# response = requests.get(url)
# html_content = response.content

# # Parse HTML with BeautifulSoup
# soup = BeautifulSoup(html_content, 'html.parser')

# # Initialize lists to hold data
# players = []
# positions = []
# ages = []
# starts = []
# ends = []
# years = []
# values = []
# aavs = []

# # Find all rows in the table
# rows = soup.find_all('tr')

# # Iterate over each row to extract data
# for row in rows:
#     cols = row.find_all('td')
#     if len(cols) > 1:  # To ensure we skip any non-relevant rows
#         player = cols[1].text.strip()
#         position = cols[2].text.strip()
#         age = cols[4].text.strip()
#         start = cols[5].text.strip()
#         end = cols[6].text.strip()
#         year_length = cols[7].text.strip()
#         value = cols[8].text.strip()
#         aav = cols[9].text.strip()

#         # Append data to lists
#         players.append(player)
#         positions.append(position)
#         ages.append(age)
#         starts.append(start)
#         ends.append(end)
#         years.append(year_length)
#         values.append(value)
#         aavs.append(aav)

# # Create a DataFrame from the lists
# NBA_contracts_2021 = pd.DataFrame({
#     'Player': players,
#     'POS': positions,
#     'Age at Signing': ages,
#     'Start': starts,
#     'End': ends,
#     'YRS': years,
#     'Value': values,
#     'AAV': aavs
# })

# # Display the DataFrame
# NBA_contracts_2021.tail()

# # Contracts signed in 2022
# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# url = 'https://www.spotrac.com/nba/contracts/_/year/2022/sort/value'

# # Fetch page content
# response = requests.get(url)
# html_content = response.content

# # Parse HTML with BeautifulSoup
# soup = BeautifulSoup(html_content, 'html.parser')

# # Initialize lists to hold data
# players = []
# positions = []
# ages = []
# starts = []
# ends = []
# years = []
# values = []
# aavs = []

# # Find all rows in the table
# rows = soup.find_all('tr')

# # Iterate over each row to extract data
# for row in rows:
#     cols = row.find_all('td')
#     if len(cols) > 1:  # To ensure we skip any non-relevant rows
#         player = cols[1].text.strip()
#         position = cols[2].text.strip()
#         age = cols[4].text.strip()
#         start = cols[5].text.strip()
#         end = cols[6].text.strip()
#         year_length = cols[7].text.strip()
#         value = cols[8].text.strip()
#         aav = cols[9].text.strip()

#         # Append data to lists
#         players.append(player)
#         positions.append(position)
#         ages.append(age)
#         starts.append(start)
#         ends.append(end)
#         years.append(year_length)
#         values.append(value)
#         aavs.append(aav)

# # Create a DataFrame from the lists
# NBA_contracts_2022 = pd.DataFrame({
#     'Player': players,
#     'POS': positions,
#     'Age at Signing': ages,
#     'Start': starts,
#     'End': ends,
#     'YRS': years,
#     'Value': values,
#     'AAV': aavs
# })

# # Display the DataFrame
# NBA_contracts_2022.tail()

# # Contracts signed in 2023
# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# url = 'https://www.spotrac.com/nba/contracts/_/year/2023/sort/value'

# # Fetch page content
# response = requests.get(url)
# html_content = response.content

# # Parse HTML with BeautifulSoup
# soup = BeautifulSoup(html_content, 'html.parser')

# # Initialize lists to hold data
# players = []
# positions = []
# ages = []
# starts = []
# ends = []
# years = []
# values = []
# aavs = []

# # Find all rows in the table
# rows = soup.find_all('tr')

# # Iterate over each row to extract data
# for row in rows:
#     cols = row.find_all('td')
#     if len(cols) > 1:  # To ensure we skip any non-relevant rows
#         player = cols[1].text.strip()
#         position = cols[2].text.strip()
#         age = cols[4].text.strip()
#         start = cols[5].text.strip()
#         end = cols[6].text.strip()
#         year_length = cols[7].text.strip()
#         value = cols[8].text.strip()
#         aav = cols[9].text.strip()

#         # Append data to lists
#         players.append(player)
#         positions.append(position)
#         ages.append(age)
#         starts.append(start)
#         ends.append(end)
#         years.append(year_length)
#         values.append(value)
#         aavs.append(aav)

# # Create a DataFrame from the lists
# NBA_contracts_2023 = pd.DataFrame({
#     'Player': players,
#     'POS': positions,
#     'Age at Signing': ages,
#     'Start': starts,
#     'End': ends,
#     'YRS': years,
#     'Value': values,
#     'AAV': aavs
# })

# # Display the DataFrame
# NBA_contracts_2023.tail()

# # Contracts signed in 2024
# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# url = 'https://www.spotrac.com/nba/contracts/_/year/2024/sort/value'

# # Fetch page content
# response = requests.get(url)
# html_content = response.content

# # Parse HTML with BeautifulSoup
# soup = BeautifulSoup(html_content, 'html.parser')

# # Initialize lists to hold data
# players = []
# positions = []
# ages = []
# starts = []
# ends = []
# years = []
# values = []
# aavs = []

# # Find all rows in the table
# rows = soup.find_all('tr')

# # Iterate over each row to extract data
# for row in rows:
#     cols = row.find_all('td')
#     if len(cols) > 1:  # To ensure we skip any non-relevant rows
#         player = cols[1].text.strip()
#         position = cols[2].text.strip()
#         age = cols[4].text.strip()
#         start = cols[5].text.strip()
#         end = cols[6].text.strip()
#         year_length = cols[7].text.strip()
#         value = cols[8].text.strip()
#         aav = cols[9].text.strip()

#         # Append data to lists
#         players.append(player)
#         positions.append(position)
#         ages.append(age)
#         starts.append(start)
#         ends.append(end)
#         years.append(year_length)
#         values.append(value)
#         aavs.append(aav)

# # Create a DataFrame from the lists
# NBA_contracts_2024 = pd.DataFrame({
#     'Player': players,
#     'POS': positions,
#     'Age at Signing': ages,
#     'Start': starts,
#     'End': ends,
#     'YRS': years,
#     'Value': values,
#     'AAV': aavs
# })

# # Display the DataFrame
# NBA_contracts_2024.tail()

"""### Importing Spotrac 2014-2024 Signings"""

from google.colab import files

uploaded = files.upload()

# Specify file name
NBA_2014_contracts = "NBA 2014 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2014 = pd.read_csv(NBA_2014_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2014 = NBA_contracts_2014.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2014['Team Signed With'] = NBA_contracts_2014['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2014.head()

uploaded = files.upload()

# Specify file name
NBA_2015_contracts = "NBA 2015 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2015 = pd.read_csv(NBA_2015_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2015 = NBA_contracts_2015.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2015['Team Signed With'] = NBA_contracts_2015['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2015.head()

uploaded = files.upload()

# Specify file name
NBA_2016_contracts = "NBA 2016 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2016 = pd.read_csv(NBA_2016_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2016 = NBA_contracts_2016.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2016['Team Signed With'] = NBA_contracts_2016['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2016.head()

uploaded = files.upload()

# Specify file name
NBA_2017_contracts = "NBA 2017 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2017 = pd.read_csv(NBA_2017_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2017 = NBA_contracts_2017.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2017['Team Signed With'] = NBA_contracts_2017['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2017.head()

uploaded = files.upload()

# Specify file name
NBA_2018_contracts = "NBA 2018 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2018 = pd.read_csv(NBA_2018_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2018 = NBA_contracts_2018.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2018['Team Signed With'] = NBA_contracts_2018['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2018.head()

uploaded = files.upload()

# Specify file name
NBA_2019_contracts = "NBA 2019 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2019 = pd.read_csv(NBA_2019_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2019 = NBA_contracts_2019.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2019['Team Signed With'] = NBA_contracts_2019['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2019.head()

uploaded = files.upload()

# Specify file name
NBA_2020_contracts = "NBA 2020 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2020 = pd.read_csv(NBA_2020_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2020 = NBA_contracts_2020.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2020['Team Signed With'] = NBA_contracts_2020['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2020.head()

uploaded = files.upload()

# Specify file name
NBA_2021_contracts = "NBA 2021 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2021 = pd.read_csv(NBA_2021_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2021 = NBA_contracts_2021.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2021['Team Signed With'] = NBA_contracts_2021['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2021.head()

uploaded = files.upload()

# Specify file name
NBA_2022_contracts = "NBA 2022 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2022 = pd.read_csv(NBA_2022_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2022 = NBA_contracts_2022.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2022['Team Signed With'] = NBA_contracts_2022['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2022.head()

uploaded = files.upload()

# Specify file name
NBA_2023_contracts = "NBA 2023 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2023 = pd.read_csv(NBA_2023_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2023 = NBA_contracts_2023.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2023['Team Signed With'] = NBA_contracts_2023['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2023.head()

uploaded = files.upload()

# Specify file name
NBA_2024_contracts = "NBA 2024 Contracts.csv"

# Read CSV file into Pandas DataFrame
NBA_contracts_2024 = pd.read_csv(NBA_2024_contracts)

# Rename columns ("wtf Spotrac")
NBA_contracts_2024 = NBA_contracts_2024.rename(columns={
    'Team\n                        Signed With': 'Team Signed With',
    'Age\n                        At Signing': 'Age At Signing'
})

# Fix duplicate team names (another "wtf Spotrac")
NBA_contracts_2024['Team Signed With'] = NBA_contracts_2024['Team Signed With'].apply(lambda x: x.split()[0])

NBA_contracts_2024.head()

"""### Consolidated DataFrame"""

# Contracts signed 2014-2024

NBA_contracts_2014_to_2024 = pd.concat([
    NBA_contracts_2014,
    NBA_contracts_2015,
    NBA_contracts_2016,
    NBA_contracts_2017,
    NBA_contracts_2018,
    NBA_contracts_2019,
    NBA_contracts_2020,
    NBA_contracts_2021,
    NBA_contracts_2022,
    NBA_contracts_2023,
    NBA_contracts_2024
], ignore_index=True)

# Convert the 'Value' & 'AAV' columns to numeric
NBA_contracts_2014_to_2024['Value'] = NBA_contracts_2014_to_2024['Value'].replace('[\$,]', '', regex=True).astype(float)
NBA_contracts_2014_to_2024['AAV'] = NBA_contracts_2014_to_2024['AAV'].replace('[\$,]', '', regex=True).astype(float)

# Convert the 'Start' column to int
NBA_contracts_2014_to_2024['Start'] = NBA_contracts_2014_to_2024['Start'].astype(int)

# Display the combined DataFrame
NBA_contracts_2014_to_2024

# Contract types to exclude
exclude_types = ['Camp Invite', 'Rookie', 'amnesty', 'ten-day', 'two-way', 'exhibit-10', 'exhibit-9', 'rest-of-season']

# Filter NBA_contracts_2014_to_2024
NBA_contracts_2014_to_2024 = NBA_contracts_2014_to_2024[~NBA_contracts_2014_to_2024['Type'].isin(exclude_types)]

NBA_contracts_2014_to_2024.info()

# Display all unique values in the 'Type' column after filtering
remaining_types = NBA_contracts_2014_to_2024['Type'].unique()
remaining_types

"""## EPM Data"""

# Import CSV's (Max) & match ratings with player contracts (EPM and/or EW before & after signing)... two seasons before, separate years & average, and one after

uploaded = files.upload()

# Specify file name
EPM_2014_data = "2014 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2014 = pd.read_csv(EPM_2014_data)

EPM_2014.head()

uploaded = files.upload()

# Specify file name
EPM_2015_data = "2015 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2015 = pd.read_csv(EPM_2015_data)

EPM_2015.head()

uploaded = files.upload()

# Specify file name
EPM_2016_data = "2016 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2016 = pd.read_csv(EPM_2016_data)

EPM_2016.head()

uploaded = files.upload()

# Specify file name
EPM_2017_data = "2017 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2017 = pd.read_csv(EPM_2017_data)

EPM_2017.head()

uploaded = files.upload()

# Specify file name
EPM_2018_data = "2018 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2018 = pd.read_csv(EPM_2018_data)

EPM_2018.head()

uploaded = files.upload()

# Specify file name
EPM_2019_data = "2019 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2019 = pd.read_csv(EPM_2019_data)

EPM_2019.head()

uploaded = files.upload()

# Specify file name
EPM_2020_data = "2020 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2020 = pd.read_csv(EPM_2020_data)

EPM_2020.head()

uploaded = files.upload()

# Specify file name
EPM_2021_data = "2021 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2021 = pd.read_csv(EPM_2021_data)

EPM_2021.head()

uploaded = files.upload()

# Specify file name
EPM_2022_data = "2022 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2022 = pd.read_csv(EPM_2022_data)

EPM_2022.head()

uploaded = files.upload()

# Specify file name
EPM_2023_data = "2023 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2023 = pd.read_csv(EPM_2023_data)

EPM_2023.head()

uploaded = files.upload()

# Specify file name
EPM_2024_data = "2024 EPM data.csv"

# Read CSV file into Pandas DataFrame
EPM_2024 = pd.read_csv(EPM_2024_data)

EPM_2024.head()

"""## Aggregate Tables into Comprehensive DataFrame"""

# League Salary Cap Data Pre-Processing

# Convert monetary columns to numeric (remove $, commas)
NBA_salary_cap['Salary Cap'] = pd.to_numeric(NBA_salary_cap['Salary Cap'].replace('[\$,]', '', regex=True), errors='coerce')
NBA_salary_cap['Luxury Tax'] = pd.to_numeric(NBA_salary_cap['Luxury Tax'].replace('[\$,]', '', regex=True), errors='coerce')
NBA_salary_cap['1st Apron'] = pd.to_numeric(NBA_salary_cap['1st Apron'].replace('[\$,]', '', regex=True), errors='coerce')
NBA_salary_cap['2nd Apron'] = pd.to_numeric(NBA_salary_cap['2nd Apron'].replace('[\$,]', '', regex=True), errors='coerce')

# Simplify 'Season' column by keeping only the first year (consistent with NBA_contracts data)
NBA_salary_cap['Season'] = NBA_salary_cap['Season'].str.split('-').str[0].astype(int)

# Display updated DataFrame
NBA_salary_cap.tail()

# Join Player Contracts Data with League Salary Cap Data


# OLD WAY FOR JUST SALARY CAP DATA IN YEAR OF CONTRACT START
# NBA_FVC = NBA_contracts_2014_to_2024.merge(
#     NBA_salary_cap,
#     left_on='Start',   # Use the 'Start' column in NBA_contracts_2014_to_2024
#     right_on='Season', # Use the 'Season' column in NBA_salary_cap
#     how='left'         # Perform a left join to keep all records from NBA_contracts_2014_to_2024
# )

# FUNCTION TO CALCULATE AVERAGE SALARY CAP DATA ACROSS ALL YEARS OF A PLAYER'S CONTRACT
def calculate_contract_average(row, salary_cap_df):
    start_year = row['Start']
    end_year = row['End']

    # Filter the salary cap data for the contract duration
    relevant_years = salary_cap_df[(salary_cap_df['Season'] >= start_year) & (salary_cap_df['Season'] <= end_year)]

    # Calculate the averages, considering NaNs
    avg_salary_cap = relevant_years['Salary Cap'].mean()
    avg_luxury_tax = relevant_years['Luxury Tax'].mean()
    avg_first_apron = relevant_years['1st Apron'].mean()

    # Calculate the average for '2nd Apron' only if there are valid (non-NaN) entries
    if relevant_years['2nd Apron'].notna().sum() > 0:
        avg_second_apron = relevant_years['2nd Apron'].mean()
    else:
        avg_second_apron = float('nan')  # Keep it as NaN if all values are NaN

    return pd.Series({
        'Contract Period': f'{start_year}-{end_year}',
        'Avg Salary Cap': avg_salary_cap,
        'Avg Luxury Tax': avg_luxury_tax,
        'Avg 1st Apron': avg_first_apron,
        'Avg 2nd Apron': avg_second_apron
    })

# Apply the function to each row
averages = NBA_contracts_2014_to_2024.apply(calculate_contract_average, axis=1, salary_cap_df=NBA_salary_cap)

# Merge the averages back to the contracts DataFrame
NBA_FVC = pd.concat([NBA_contracts_2014_to_2024, averages], axis=1)

NBA_FVC.head()

# Address Naming Inconsistencies Across Spotrac + Dunks & Threes
name_corrections = {
    'A.J. Griffin': 'AJ Griffin',
    'Cameron Thomas': 'Cam Thomas',
    "Nah'Shon Hyland": 'Bones Hyland',
    'R.J. Barrett': 'RJ Barrett',
    'RJ Hampton': 'R.J. Hampton',
    'Herb Jones': 'Herbert Jones',
    'PJ Washington': 'P.J. Washington',
    'Bruce Brown Jr.': 'Bruce Brown',
    'Dennis Schröder': 'Dennis Schroder',
    'Vincent Williams Jr.': 'Vince Williams Jr.',
    'Nicolas Claxton': 'Nic Claxton',
    'C.J. McCollum': 'CJ McCollum',
    'Sviatoslav Mykhailiuk': 'Svi Mykhailiuk',
    'C.J. Miles': 'CJ Miles',
    'Jose Barea': 'J.J. Barea',
    'J.J. Redick': 'JJ Redick',
    'J.R. Smith': 'JR Smith',
    'Ishmael Smith': 'Ish Smith',
    'Ishmail Wainright': 'Ish Wainright',
    'Enes Freedom': 'Enes Kanter',
    'Louis Williams': 'Lou Williams',
    'Louis Amundson': 'Lou Amundson',
    'B.J. Johnson': 'BJ Johnson',
    'P.J. Dozier': 'PJ Dozier',
    'K.J. McDaniels': 'KJ McDaniels',
    'DJ Wilson': 'D.J. Wilson',
    "Jae’Sean Tate": "Jae'Sean Tate",
    'Mohamed Bamba': 'Mo Bamba',
    'Kevin Knox': 'Kevin Knox II',
    'G.G. Jackson': 'GG Jackson II',
    'Harry Giles': 'Harry Giles III',
    'Nene Hilario': 'Nene'
}

# Apply corrections to 'Player' column in NBA_FVC
NBA_FVC['Player'] = NBA_FVC['Player'].replace(name_corrections)

# Join Financial Data with Player Production Data

import numpy as np

def fill_epm_ew_data(row, epm_dataframes):
    start_year = row['Start']
    end_year = row['End']
    name = row['Player']

    # Ensure start_year and end_year are integers and not NaN
    if pd.isna(start_year) or pd.isna(end_year):
        return row  # Return the row unchanged if start_year or end_year is NaN

    start_year = int(start_year)
    end_year = int(end_year)

    # Define the columns to be filled for before signing
    columns_years_before = {
        'EPM_2Y_Before': start_year - 1,  # Two years before = 1 season before start year
        'EPM_1Y_Before': start_year,      # One year before = start year
        'EW_2Y_Before': start_year - 1,
        'EW_1Y_Before': start_year
    }

    # Fill the columns before signing
    for column, year in columns_years_before.items():
        epm_year = f'EPM_{year}'
        if epm_year in epm_dataframes:
            epm_df = epm_dataframes[epm_year]
            player_data = epm_df[epm_df['name'] == name]

            if not player_data.empty:
                if 'EPM' in column:
                    row[column] = player_data['epm'].values[0]
                elif 'EW' in column:
                    row[column] = player_data['ewins'].values[0]
            else:
                row[column] = np.nan
        else:
            row[column] = np.nan

    # Fill the columns after signing based on the length of the contract
    for year_offset in range(1, end_year - start_year + 2):
        epm_year = f'EPM_{start_year + year_offset}'
        if epm_year in epm_dataframes:
            epm_df = epm_dataframes[epm_year]
            player_data = epm_df[epm_df['name'] == name]
            epm_column = f'EPM_{year_offset}Y_After'
            ew_column = f'EW_{year_offset}Y_After'

            if not player_data.empty:
                row[epm_column] = player_data['epm'].values[0]
                row[ew_column] = player_data['ewins'].values[0]
            else:
                row[epm_column] = np.nan
                row[ew_column] = np.nan
        else:
            row[f'EPM_{year_offset}Y_After'] = np.nan
            row[f'EW_{year_offset}Y_After'] = np.nan

    return row

# Store EPM dataframes in single dictionary
epm_dataframes = {
    'EPM_2014': EPM_2014,
    'EPM_2015': EPM_2015,
    'EPM_2016': EPM_2016,
    'EPM_2017': EPM_2017,
    'EPM_2018': EPM_2018,
    'EPM_2019': EPM_2019,
    'EPM_2020': EPM_2020,
    'EPM_2021': EPM_2021,
    'EPM_2022': EPM_2022,
    'EPM_2023': EPM_2023,
    'EPM_2024': EPM_2024
}

# Apply function to each row in NBA_FVC
NBA_FVC = NBA_FVC.apply(fill_epm_ew_data, axis=1, epm_dataframes=epm_dataframes)
NBA_FVC.head()

def fill_additional_stats_before(row, epm_dataframes):
    start_year = row['Start']
    name = row['Player']

    # Ensure start_year is an integer and not NaN
    if pd.isna(start_year):
        return row  # Return the row unchanged if start_year is NaN

    start_year = int(start_year)

    # Define the columns to be filled for the stats (gp, usg, mpg) for two years before signing
    stats_columns_before = {
        'GP_2Y_Before': start_year - 1,
        'USG_2Y_Before': start_year - 1,
        'MPG_2Y_Before': start_year - 1,
        'GP_1Y_Before': start_year,
        'USG_1Y_Before': start_year,
        'MPG_1Y_Before': start_year
    }

    # Fill the columns with data from two years before signing
    for column, year in stats_columns_before.items():
        epm_year = f'EPM_{year}'
        if epm_year in epm_dataframes:
            epm_df = epm_dataframes[epm_year]
            player_data = epm_df[epm_df['name'] == name]

            if not player_data.empty:
                if 'GP' in column:
                    row[column] = player_data['gp'].values[0]
                elif 'USG' in column:
                    row[column] = player_data['usg'].values[0]
                elif 'MPG' in column:
                    row[column] = player_data['mpg'].values[0]
            else:
                row[column] = np.nan
        else:
            row[column] = np.nan

    return row

# Apply function to each row in NBA_FVC
NBA_FVC = NBA_FVC.apply(fill_additional_stats_before, axis=1, epm_dataframes=epm_dataframes)

# Display the relevant columns to check the changes
NBA_FVC[['Player', 'GP_2Y_Before', 'USG_2Y_Before', 'MPG_2Y_Before', 'GP_1Y_Before', 'USG_1Y_Before', 'MPG_1Y_Before']].head()

# Define desired column order
desired_order = [
    'Player', 'Pos', 'Team Signed With', 'Age At Signing', 'Start', 'End', 'Yrs', 'Value', 'AAV',
    'Type', 'Signed Date', 'Contract Period', 'Avg Salary Cap', 'Avg Luxury Tax',
    'Avg 1st Apron', 'Avg 2nd Apron', 'GP_2Y_Before', 'GP_1Y_Before', 'MPG_2Y_Before', 'MPG_1Y_Before',
    'USG_2Y_Before', 'USG_1Y_Before', 'EPM_2Y_Before', 'EPM_1Y_Before',
    'EPM_1Y_After', 'EPM_2Y_After', 'EPM_3Y_After', 'EPM_4Y_After', 'EPM_5Y_After', 'EW_2Y_Before',
    'EW_1Y_Before', 'EW_1Y_After', 'EW_2Y_After', 'EW_3Y_After', 'EW_4Y_After', 'EW_5Y_After'
]

# Reorder columns
NBA_FVC = NBA_FVC[desired_order]

NBA_FVC.head()

"""## Export DataFrame to CSV"""

# Save DataFrame to a CSV file (for further data cleaning & feature engineering in excel)
NBA_FVC.to_csv('NBA_FVC_New_Features.csv', index=False, mode='w')

"""## Min & Max Contract Indicators

### Maximum Contracts 2023-2031
"""

#Minimum Contract
#Maximum Contract
#Indicators
#Look into Darko --> high tier draft prospects

import requests
import pandas as pd
from bs4 import BeautifulSoup

url = "https://www.spotrac.com/nba/cba/maximum"

response = requests.get(url)


html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

tables = soup.find_all('table', {'id': 'table'})

table2023_2030 = tables[0]

#2023-2030 CBA rules
percent_cap = []
year2023_24 = []
year2024_25 = []
year2025_26 = []
year2026_27 = []
year2027_28 = []
year2028_29 = []
year2029_30 = []
year2030_31 = []

#print("Table found:\n", table.prettify())

rows = table2023_2030.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    if len(cols) == 9:
        percentofcap = cols[0].text.strip()
        year202324 = cols[1].text.strip()
        year202425 = cols[2].text.strip()
        year202526 = cols[3].text.strip()
        year202627 = cols[4].text.strip()
        year202728 = cols[5].text.strip()
        year202829 = cols[6].text.strip()
        year202930 = cols[7].text.strip()
        year203031 = cols[8].text.strip()

        percent_cap.append(percentofcap)
        year2023_24.append(year202324)
        year2024_25.append(year202425)
        year2025_26.append(year202526)
        year2026_27.append(year202627)
        year2027_28.append(year202728)
        year2028_29.append(year202829)
        year2029_30.append(year202930)
        year2030_31.append(year203031)

Maximum_contracts2023_2031 = pd.DataFrame({
            'Percent of Cap Space': percent_cap,
            '2023-24': year2023_24,
            '2024-25': year2024_25,
            '2025-26': year2025_26,
            '2026-27': year2026_27,
            '2027-28': year2027_28,
            '2028-29': year2028_29,
            '2029-30': year2029_30,
            '2030-31': year2030_31
        })

Maximum_contracts2023_2031

"""### Maximum Contracts 2017 - 2022"""

import requests
import pandas as pd
from bs4 import BeautifulSoup
import numpy as np
import statsmodels.formula.api as smf
import matplotlib.pyplot
import seaborn as sns


url = "https://www.spotrac.com/nba/cba/maximum"

response = requests.get(url)


html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

tables = soup.find_all('table', {'id': 'table'})

table2017_2022 = tables[1]

#2017-2022 CBA rules
percent_cap = []
year2017_18 = []
year2018_19 = []
year2019_20 = []
year2020_21 = []
year2021_22 = []
year2022_23 = []


#print("Table found:\n", table.prettify())

rows = table2017_2022.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    if len(cols) == 7:
        percentofcap = cols[0].text.strip()
        year201718 = cols[1].text.strip()
        year201819 = cols[2].text.strip()
        year201920 = cols[3].text.strip()
        year202021 = cols[4].text.strip()
        year202122 = cols[5].text.strip()
        year202223 = cols[6].text.strip()

        percent_cap.append(percentofcap)
        year2017_18.append(year201718)
        year2018_19.append(year201819)
        year2019_20.append(year201920)
        year2020_21.append(year202021)
        year2021_22.append(year202122)
        year2022_23.append(year202223)

Maximum_contracts2017_2022 = pd.DataFrame({
            'Percent of Cap Space': percent_cap,
            '2017-18': year2017_18,
            '2018-19': year2018_19,
            '2019-20': year2019_20,
            '2020-21': year2020_21,
            '2021-22': year2021_22,
            '2022-23': year2022_23,
        })

Maximum_contracts2017_2022

"""### Maximum Contracts 2011 - 2016

"""

import requests
import pandas as pd
from bs4 import BeautifulSoup
import numpy as np
import statsmodels.formula.api as smf
import matplotlib.pyplot
import seaborn as sns


url = "https://www.spotrac.com/nba/cba/maximum"

response = requests.get(url)


html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

tables = soup.find_all('table', {'id': 'table'})

table2011_2016 = tables[2]

#2011-2016 CBA rules
percent_cap = []
year2011_12 = []
year2012_13 = []
year2013_14 = []
year2014_15 = []
year2015_16 = []
year2016_17 = []


#print("Table found:\n", table.prettify())

rows = table2011_2016.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    if len(cols) == 7:
        percentofcap = cols[0].text.strip()
        year201112 = cols[1].text.strip()
        year201213 = cols[2].text.strip()
        year201314 = cols[3].text.strip()
        year201415 = cols[4].text.strip()
        year201516 = cols[5].text.strip()
        year201617 = cols[6].text.strip()

        percent_cap.append(percentofcap)
        year2011_12.append(year201112)
        year2012_13.append(year201213)
        year2013_14.append(year201314)
        year2014_15.append(year201415)
        year2015_16.append(year201516)
        year2016_17.append(year201617)

Maximum_contracts2011_2016 = pd.DataFrame({
            'Percent of Cap Space': percent_cap,
            '2011-12': year2011_12,
            '2012-13': year2012_13,
            '2013-14': year2013_14,
            '2014-15': year2014_15,
            '2015-16': year2015_16,
            '2016-17': year2016_17,
        })

Maximum_contracts2011_2016

"""### Minimum Contracts 2022 - 2028"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

url = "https://www.spotrac.com/nba/cba/minimum"

response = requests.get(url)

html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

tables = soup.find_all('table', {'id': 'table'})

table2022_2028 = tables[0]

#2022-2030 CBA rules
yearsservice = []
year2022 = []
year2023 = []
year2024 = []
year2025 = []
year2026 = []
year2027 = []
year2028 = []

#print("Table found:\n", table.prettify())

rows = table2022_2028.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    if len(cols) == 8:
        service = cols[0].text.strip()
        years2022 = cols[1].text.strip()
        years2023 = cols[2].text.strip()
        years2024 = cols[3].text.strip()
        years2025 = cols[4].text.strip()
        years2026 = cols[5].text.strip()
        years2027 = cols[6].text.strip()
        years2028 = cols[7].text.strip()

        yearsservice.append(service)
        year2022.append(years2022)
        year2023.append(years2023)
        year2024.append(years2024)
        year2025.append(years2025)
        year2026.append(years2026)
        year2027.append(years2027)
        year2028.append(years2028)

Minimum_contracts2022_2028 = pd.DataFrame({
            'Years of Service': yearsservice,
            '2022': year2022,
            '2023': year2023,
            '2024': year2024,
            '2025': year2025,
            '2026': year2026,
            '2027': year2027,
            '2028': year2028,
        })

Minimum_contracts2022_2028

"""### Minimum Contracts 2017 - 2021"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

url = "https://www.spotrac.com/nba/cba/minimum"

response = requests.get(url)

html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

tables = soup.find_all('table', {'id': 'table'})

table2017_2021 = tables[1]

#2017-2021 CBA rules
yearsservice = []
year2017 = []
year2018 = []
year2019 = []
year2020 = []
year2021 = []

#print("Table found:\n", table.prettify())

rows = table2017_2021.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    if len(cols) == 6:
        service = cols[0].text.strip()
        years2017 = cols[1].text.strip()
        years2018 = cols[2].text.strip()
        years2019 = cols[3].text.strip()
        years2020 = cols[4].text.strip()
        years2021 = cols[5].text.strip()


        yearsservice.append(service)
        year2017.append(years2017)
        year2018.append(years2018)
        year2019.append(years2019)
        year2020.append(years2020)
        year2021.append(years2021)


Minimum_contracts2017_2021 = pd.DataFrame({
            'Years of Service': yearsservice,
            '2017': year2017,
            '2018': year2018,
            '2019': year2019,
            '2020': year2020,
            '2021': year2021,

        })

Minimum_contracts2017_2021

"""### Minimum Contracts 2011 - 2016"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

url = "https://www.spotrac.com/nba/cba/minimum"

response = requests.get(url)

html_content = response.content

soup = BeautifulSoup(html_content, 'html.parser')

tables = soup.find_all('table', {'id': 'table'})

table2011_2016 = tables[2]

#2011-2016 CBA rules
yearsservice = []
year2011 = []
year2012 = []
year2013 = []
year2014 = []
year2015 = []
year2016 = []


#print("Table found:\n", table.prettify())

rows = table2011_2016.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    if len(cols) == 7:
        service = cols[0].text.strip()
        years2011 = cols[1].text.strip()
        years2012 = cols[2].text.strip()
        years2013 = cols[3].text.strip()
        years2014 = cols[4].text.strip()
        years2015 = cols[5].text.strip()
        years2016 = cols[6].text.strip()


        yearsservice.append(service)
        year2011.append(years2011)
        year2012.append(years2012)
        year2013.append(years2013)
        year2014.append(years2014)
        year2015.append(years2015)
        year2016.append(years2016)


Minimum_contracts2011_2016 = pd.DataFrame({
            'Years of Service': yearsservice,
            '2011': year2011,
            '2012': year2012,
            '2013': year2013,
            '2014': year2014,
            '2015': year2015,
            '2016': year2016,

        })

Minimum_contracts2011_2016

"""### Indicators for Extensions"""

import requests
import pandas as pd
from bs4 import BeautifulSoup


years = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2021, 2022, 2023, 2024]

tables = []

for year in years:
  url = f"https://www.spotrac.com/nba/contracts/extensions/_/year/{year}/sort/value"

  response = requests.get(url)
  html_content = response.content

  soup = BeautifulSoup(html_content, 'html.parser')

  rows = soup.find_all('tr')

  table = []

  for row in rows[1:]:
    cols = row.find_all('td')

    row_data = {
        "Rank" : cols[0].text.strip(),
        "Player" : cols[1].text.strip(),
        "Position" : cols[2].text.strip(),
        "Team" : cols[3].text.strip(),
        "Age" : cols[4].text.strip(),
        "Year" : cols[5].text.strip(),
        "Value" : cols[6].text.strip(),
        "AAV" : cols[7].text.strip(),
        "Practical GTD" : cols[8].text.strip(),
        "Contract Types" : cols[9].text.strip(),
    }
    row_data["Max Contract Indicator"] = 1 if "Maximum" in row_data["Contract Types"] else 0

    table.append(row_data)

  df = pd.DataFrame(table)
  tables.append(df)

tables[1]

"""### Data sweeping Draft Years

"""

# from requests_html import AsyncHTMLSession
# import pandas as pd
# import asyncio

# # Initialize the asynchronous HTML session
# session = AsyncHTMLSession()

# years = list(range(1998, 2025))  # From 1998 to 2024
# draft_data = []  # List to hold all draft data

# async def fetch_draft_data(year):
#     url = f"https://www.nba.com/stats/draft/history?Season={year}"

#     response = await session.get(url)

#     # Render JavaScript to load dynamic content with extended timeout
#     await response.html.arender(sleep=2, timeout=20)  # Set timeout to 20 seconds

#     # Find the table rows that contain the drafted players' information
#     rows = response.html.find('table tbody tr')

#     # Loop through each row and extract the player's name
#     for row in rows:
#         cols = row.find('td')
#         if len(cols) > 0:
#             player_name = cols[0].text.strip()  # Player's name is usually in the first column
#             draft_data.append({"Year": year, "Player": player_name})

# # Create the event loop to run the tasks asynchronously
# async def main():
#     tasks = [fetch_draft_data(year) for year in years]
#     await asyncio.gather(*tasks)

# # Run the asynchronous scraping
# await main()

# # Convert the list into a DataFrame
# df = pd.DataFrame(draft_data)

# # Print the DataFrame
# print(df)

# # Optionally, save it to a CSV file
# df.to_csv('nba_draft_1998_2024.csv', index=False)

"""Ignore this for now; created since there were to many requests to the URL"""

# import requests
# import pandas as pd
# from bs4 import BeautifulSoup
# import time
# from requests.adapters import HTTPAdapter
# from urllib3.util.retry import Retry

# years = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]

# tables = []
# headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

# # Setup retry strategy
# retry_strategy = Retry(
#     total=3,  # Number of retries
#     backoff_factor=1,  # Wait time between retries (e.g., 1s, 2s, 4s)
#     status_forcelist=[429, 500, 502, 503, 504],  # Retry on these status codes
#     allowed_methods=["HEAD", "GET", "OPTIONS"]  # Specify methods to retry
# )
# adapter = HTTPAdapter(max_retries=retry_strategy)
# http = requests.Session()
# http.mount("https://", adapter)

# for year in years:
#     url = f"https://www.spotrac.com/nba/contracts/extensions/_/year/{year}/sort/value"

#     try:
#         response = http.get(url, headers=headers, timeout=30)
#         response.raise_for_status()  # Raises an HTTPError for bad responses

#         html_content = response.content
#         soup = BeautifulSoup(html_content, 'html.parser')
#         rows = soup.find_all('tr')

#         table = []

#         for row in rows[1:]:
#             cols = row.find_all('td')

#             row_data = {
#                 "Rank": cols[0].text.strip(),
#                 "Player": cols[1].text.strip(),
#                 "Position": cols[2].text.strip(),
#                 "Team": cols[3].text.strip(),
#                 "Age": cols[4].text.strip(),
#                 "Year": cols[5].text.strip(),
#                 "Value": cols[6].text.strip(),
#                 "AAV": cols[7].text.strip(),
#                 "Practical GTD": cols[8].text.strip(),
#                 "Contract Types": cols[9].text.strip(),
#             }
#             row_data["Is_Maximum"] = 1 if "Maximum" in row_data["Contract Types"] else 0
#             table.append(row_data)

#         df = pd.DataFrame(table)
#         tables.append(df)

#     except requests.exceptions.RequestException as e:
#         print(f"Error fetching data for {year}: {e}")

#     time.sleep(2)  # Respectful delay between requests

# # Example output
# if tables:
#     print(tables[0].head())

"""### Indicators For Contracts

"""

#indicator value for contracts
#create a manual range for max contracts of every year and then run through new df to see if contract value fits in that range

"""# Importing Finalized Data (CSV)"""

# # ideally, just a placeholder - better ways to import data without manually selecting a file each runtime

# uploaded = files.upload()

# # Specify file name
# NBA_FVC_data = "NBA_FVC.csv"

# # Read CSV file into Pandas DataFrame
# NBA_FVC = pd.read_csv(NBA_FVC_data)

"""## Omitting Unnecessary Contracts (run after from here)

"""

from google.colab import files
import pandas as pd
import io

# Upload the file
uploaded = files.upload()

# Get the actual filename
actual_filename = list(uploaded.keys())[0]

# Load the CSV file into a DataFrame
df = pd.read_csv(io.StringIO(uploaded[actual_filename].decode('utf-8')))

# Remove the first row if it's not needed (here it's not removed, but you can adjust this line as needed)
df = df.iloc[0:]

# Filter the data based on the new conditions
initial_filter_data = []
omitted_data = []

for index, row in df.iterrows():
    # Condition to check for omitting data
    omit_condition_1 = (pd.isna(row['EPM_2Y_Before']) and pd.isna(row['EPM_1Y_Before']))
    omit_condition_2 = (pd.isna(row['EPM_1Y_After']) and pd.isna(row['EPM_2Y_After']) and
                        pd.isna(row['EPM_3Y_After']) and pd.isna(row['EPM_4Y_After']) and
                        pd.isna(row['EPM_5Y_After']) and row['Start'] != 2024)

    if omit_condition_1 or omit_condition_2:
        omitted_data.append(row)
    else:
        initial_filter_data.append(row)

# Create DataFrames for filtered and omitted data
NBA_FVC_initial_filter = pd.DataFrame(initial_filter_data)
NBA_FVC_omitted = pd.DataFrame(omitted_data)

# # Save the filtered DataFrame to a new CSV file
# NBA_FVC_initial_filter.to_csv('initial_filter_data.csv', index=False)

# # Save the omitted DataFrame to a separate CSV file
# NBA_FVC_omitted.to_csv('omitted_data.csv', index=False)

# Display the first few rows of the filtered DataFrame
NBA_FVC_initial_filter.head()

"""### Data Pre-Processing"""

# Convert dollar columns to decimals
NBA_FVC_initial_filter['Avg_Salary_Cap'] = NBA_FVC_initial_filter['Avg_Salary_Cap'].replace({'\$': '', ',': '', '%': ''}, regex=True).astype(float)
NBA_FVC_initial_filter['Avg_Luxury_Tax'] = pd.to_numeric(NBA_FVC_initial_filter['Avg_Luxury_Tax'].replace('[\$,]', '', regex=True), errors='coerce')
NBA_FVC_initial_filter['Avg_1st_Apron'] = pd.to_numeric(NBA_FVC_initial_filter['Avg_1st_Apron'].replace('[\$,]', '', regex=True), errors='coerce')
NBA_FVC_initial_filter['Avg_2nd_Apron'] = pd.to_numeric(NBA_FVC_initial_filter['Avg_2nd_Apron'].replace('[\$,]', '', regex=True), errors='coerce')
NBA_FVC_initial_filter['AAV'] = NBA_FVC_initial_filter['AAV'].replace({'\$': '', ',': ''}, regex=True).astype(float)
NBA_FVC_initial_filter['Value'] = NBA_FVC_initial_filter['Value'].replace({'\$': '', ',': ''}, regex=True).astype(float)

# Convert percentage columns to decimals
NBA_FVC_initial_filter['AAV / Salary Cap'] = NBA_FVC_initial_filter['AAV / Salary Cap'].replace({'%': ''}, regex=True).astype(float) / 100
NBA_FVC_initial_filter['AAV / Luxury Tax'] = NBA_FVC_initial_filter['AAV / Luxury Tax'].replace({'%': ''}, regex=True).astype(float) / 100
NBA_FVC_initial_filter['AAV / 1st Apron'] = NBA_FVC_initial_filter['AAV / 1st Apron'].replace({'%': ''}, regex=True).astype(float) / 100
NBA_FVC_initial_filter['AAV / 2nd Apron'] = NBA_FVC_initial_filter['AAV / 2nd Apron'].replace({'%': ''}, regex=True).astype(float) / 100

NBA_FVC_initial_filter['USG_2Y_Before'] = NBA_FVC_initial_filter['USG_2Y_Before'].replace({'%': ''}, regex=True).astype(float) / 100
NBA_FVC_initial_filter['USG_1Y_Before'] = NBA_FVC_initial_filter['USG_1Y_Before'].replace({'%': ''}, regex=True).astype(float) / 100
NBA_FVC_initial_filter['Avg_USG_Before'] = NBA_FVC_initial_filter['Avg_USG_Before'].replace({'%': ''}, regex=True).astype(float) / 100
NBA_FVC_initial_filter['W_Avg_USG_Before'] = NBA_FVC_initial_filter['W_Avg_USG_Before'].replace({'%': ''}, regex=True).astype(float) / 100

# Create a new column 'AAV vs Cap Space' that shows 1 if 'AAV' is >= 25% of 'Average Cap Space', otherwise 0
NBA_FVC_initial_filter['Max Contract Indicator Upgrade'] = NBA_FVC_initial_filter.apply(lambda row: 1 if row['AAV'] >= (0.25 * row['Avg_Salary_Cap']) else 0, axis=1)

# Display the first few rows of the updated DataFrame
NBA_FVC_initial_filter.head()

"""# Exploratory Analysis & Feature Engineering

## Creating EPM/EW After Columns & Handling Unfisnished Contracts
"""

# Convert EPM & EW 'Before' to Averages (weighted, unweighted, difference between Y2 and Y1) --- did this in google sheets
# Create AAV vs. Avg. Cap Constraints Columns --- did this in google sheets

import numpy as np

# Convert EPM & EW 'After' to Averages (only consider applicable years)
ew_after_columns = ['EW_1Y_After', 'EW_2Y_After', 'EW_3Y_After', 'EW_4Y_After', 'EW_5Y_After']
epm_after_columns = ['EPM_1Y_After', 'EPM_2Y_After', 'EPM_3Y_After', 'EPM_4Y_After', 'EPM_5Y_After']

def calculate_average_after(row, columns):
    valid_values = row[columns].dropna()  # Drop null values
    if len(valid_values) > 0:
        return valid_values.mean()  # Calculate the average of non-null values
    else:
        return np.nan  # Return NaN if no valid values

NBA_FVC_initial_filter['Avg_EPM_After'] = NBA_FVC_initial_filter.apply(lambda row: calculate_average_after(row, epm_after_columns), axis=1)
NBA_FVC_initial_filter['Avg_EW_After'] = NBA_FVC_initial_filter.apply(lambda row: calculate_average_after(row, ew_after_columns), axis=1)


# Convert Positon to Guard, Wing, Big (either separate models or 1, 2, 3 numerical indicators) -- might want to further tune manually later
# Define a function to map position to role (1 = Guard, 2 = Wing, 3 = Big)
# def map_position_to_role(position):
#     if position in ['PG', 'SG']:
#         return 1  # Guard
#     elif position in ['C']:
#         return 3  # Big
#     else:
#         return 2  # Wing

# # Create a new 'Role' column based on the position mapping
# NBA_FVC_initial_filter['Role'] = NBA_FVC_initial_filter['Pos'].apply(map_position_to_role)

# Display the updated dataframe with the new binary columns
NBA_FVC_initial_filter[['Player', 'Pos', 'Role', 'AAV / Salary Cap', 'Avg_USG_Before', 'Avg_EPM_After', 'Avg_EW_After']].head()

# # Set N/A EW values (that fall during length of contract) to 0

# ew_after_columns = ['EW_1Y_After', 'EW_2Y_After', 'EW_3Y_After', 'EW_4Y_After', 'EW_5Y_After']

#  # Function to fill missing EW_After values within contract length
# def fill_missing_ew(row):
#      start_year = row['Start']  # Get the contract start year
#      contract_years = row['Yrs']  # Number of contract years

#      # Skip filling with zeroes if the contract starts in 2024 (upcoming season)
#      if start_year == 2024:
#          return row

# #    # Loop through each EW_After column
#      for i in range(contract_years):  # Only consider the years within the contract length
#          ew_column = ew_after_columns[i]
#          if np.isnan(row[ew_column]):  # Check if the value is NaN (missing)
#              row[ew_column] = 0        # Set missing values to 0 within contract period

#      return row

# # # Apply function to each row in dataframe
# NBA_FVC_initial_filter = NBA_FVC_initial_filter.apply(fill_missing_ew, axis=1)

NBA_FVC_initial_filter.info()

# FILTERING OUT UNFINISHED CONTRACTS

NBA_FVC_filtered = NBA_FVC_initial_filter[NBA_FVC_initial_filter['C_Over'] == 1].copy()

print(f"Number of observations remaining after removing unfinished contracts: {len(NBA_FVC_filtered)}")

"""## Addressing Age Survivorship Bias

### EPM
"""

# Check for missing values in the relevant columns
missing_values = NBA_FVC_filtered[['Avg_EPM_After', 'Avg_EW_After', 'Age_At_Start', 'Median_Age',
                                   'W_Avg_Min_Before', 'W_Avg_USG_Before', 'Role']].isnull().sum()
print(missing_values)

# DETERMINING THE IMPACT OF AGE ON EPM PERFORMANCE, PER PLAYER (i.e. AGE CURVES PER PLAYER)
age_df = NBA_FVC_filtered.copy()

# Group data by player
player_age_groups = age_df.groupby('Player')

# Initialize variables to store total correlation and player count
total_correlation = 0
player_count = 0

# Calculate correlation between Median_Age and Avg_EPM_After per player
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        # Check if there's no variation in Median_Age or Avg_EPM_After
        if np.std(group['Median_Age']) == 0 or np.std(group['Avg_EPM_After']) == 0:
            continue  # Skip this group if there's no variation
        correlation = group['Median_Age'].corr(group['Avg_EPM_After'])
        if pd.notna(correlation):  # Check if correlation is not NaN
            total_correlation += correlation
            player_count += 1

# Calculate the average correlation
if player_count > 0:
    average_correlation = total_correlation / player_count
else:
    average_correlation = None  # In case there were no valid correlations

# Print the average correlation = TRUE AVG. IMPACT OF AGE ON EPM PERFORMANCE
print(f"Average correlation between Median_Age and Avg_EPM_After: {average_correlation:.4f}")

# AGE CURVE GRAPHS (Median_Age vs. Avg_EPM_After)

import plotly.graph_objects as go
from scipy.optimize import curve_fit

# Function to fit a quadratic curve
def quadratic_fit(x, a, b, c):
    return a * x**2 + b * x + c

# Create the plot
fig = go.Figure()

all_ages = []
all_epms = []

# Iterate through all qualified players
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        ages = group['Median_Age']
        epms = group['Avg_EPM_After']

        # Add individual player curve
        fig.add_trace(go.Scatter(x=ages, y=epms, mode='markers+lines', name=player,
                                 line=dict(color='lightblue', width=1),
                                 marker=dict(color='lightblue', size=4),
                                 opacity=0.3, showlegend=False))

        all_ages.extend(ages)
        all_epms.extend(epms)

# Fit a quadratic curve to all data points
all_ages = np.array(all_ages)
all_epms = np.array(all_epms)
popt, _ = curve_fit(quadratic_fit, all_ages, all_epms)

# Generate points for the fitted curve
x_fit = np.linspace(min(all_ages), max(all_ages), 100)
y_fit = quadratic_fit(x_fit, *popt)

# Add the fitted curve
fig.add_trace(go.Scatter(x=x_fit, y=y_fit, mode='lines', name='Quadratic Fit',
                         line=dict(color='red', width=3)))

# Update layout
fig.update_layout(title='Age Curves for All Qualified Players',
                  xaxis_title='Median Age',
                  yaxis_title='Avg EPM After',
                  showlegend=True)

# Show the plot
fig.show()

# Print the quadratic fit parameters
print(f"Quadratic fit: y = {popt[0]:.4f}x^2 + {popt[1]:.4f}x + {popt[2]:.4f}")

# Calculate the age of peak performance
peak_age = -popt[1] / (2 * popt[0])
print(f"Estimated age of peak EPM performance: {peak_age:.2f}")

# Plotting Packages
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

# Create a long-format dataset
Peak_Age_EPM = NBA_FVC_initial_filter.copy()

long_df = pd.melt(Peak_Age_EPM,
                  id_vars=['Player', 'Age_At_Start'],
                  value_vars=['EPM_2Y_Before', 'EPM_1Y_Before', 'EPM_1Y_After', 'EPM_2Y_After', 'EPM_3Y_After', 'EPM_4Y_After', 'EPM_5Y_After'],
                  var_name='Season',
                  value_name='EPM')

def calculate_age(row):
    age_at_start = row['Age_At_Start']
    season = row['Season']
    if season == 'EPM_2Y_Before':
        return age_at_start - 2
    elif season == 'EPM_1Y_Before':
        return age_at_start - 1
    elif season == 'EPM_1Y_After':
        return age_at_start
    elif season == 'EPM_2Y_After':
        return age_at_start + 1
    elif season == 'EPM_3Y_After':
        return age_at_start + 2
    elif season == 'EPM_4Y_After':
        return age_at_start + 3
    elif season == 'EPM_5Y_After':
        return age_at_start + 4
    else:
        return age_at_start

long_df['Age'] = long_df.apply(calculate_age, axis=1)

# Group by Age and calculate average EPM
avg_epm_by_age = long_df.groupby('Age')['EPM'].mean().reset_index()

# Create the Plotly bar graph
fig = px.bar(avg_epm_by_age, x='Age', y='EPM', title='Average EPM by Age')
fig.update_layout(xaxis_title='Age', yaxis_title='Average EPM')

# Show the plot
fig.show()

# DETERMINING THE "POSITIVE" IMPACT OF AGE ON EPM PERFORMANCE, PER PLAYER, APPROACHING PEAK AGE 29

from sklearn.linear_model import LinearRegression

# Define the peak age
peak_age = 29

# Group data by player
player_age_groups = age_df.groupby('Player')

# Initialize variables to store total positive correlation, regression coefficient, and player count
total_positive_correlation = 0
total_regression_coefficient = 0
positive_player_count = 0

# Calculate correlation and regression coefficient between Median_Age and Avg_EPM_After per player
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        # Consider only players below peak or at peak (to focus on the positive trend)
        positive_impact_group = group[group['Median_Age'] <= peak_age]

        # Check if the positive_impact_group has at least one row
        if len(positive_impact_group) == 0:
            continue  # Skip this group if it has no rows

        # Check if there's no variation in Median_Age or Avg_EPM_After
        if np.std(positive_impact_group['Median_Age']) == 0 or np.std(positive_impact_group['Avg_EPM_After']) == 0:
            continue  # Skip this group if there's no variation

        # Calculate the correlation
        correlation = positive_impact_group['Median_Age'].corr(positive_impact_group['Avg_EPM_After'])

        # Calculate the regression coefficient (slope)
        X = positive_impact_group[['Median_Age']].values.reshape(-1, 1)
        y = positive_impact_group['Avg_EPM_After'].values

        if len(X) > 1 and len(y) > 1:  # Ensure there are enough samples for regression
            reg = LinearRegression().fit(X, y)
            regression_coefficient = reg.coef_[0]  # Get the slope of the regression line

            if pd.notna(correlation):  # Check if correlation is not NaN
                total_positive_correlation += correlation
                total_regression_coefficient += regression_coefficient
                positive_player_count += 1

# Calculate the average positive correlation and regression coefficient
if positive_player_count > 0:
    average_positive_correlation = total_positive_correlation / positive_player_count
    average_regression_coefficient = total_regression_coefficient / positive_player_count
else:
    average_positive_correlation = None  # In case there were no valid correlations
    average_regression_coefficient = None  # In case there were no valid regression coefficients

# Print the average positive correlation and regression coefficient
print(f"Average correlation between Median_Age and Avg_EPM_After approaching peak age 29: {average_positive_correlation:.4f}")
print(f"Average regression coefficient for Median_Age on Avg_EPM_After approaching peak age 29: {average_regression_coefficient:.4f}\n")
print(f"these results are counter-intuitive; likely a byproduct of rookie max extensions + not having rookie contract performance data (our data isn't capturing career progression from start to peak)")

# DETERMINING THE ADVERSE IMPACT OF AGE ON EPM PERFORMANCE, PER PLAYER, POST PEAK AGE 29

# Define the peak age
peak_age = 29

# Group data by player
player_age_groups = age_df.groupby('Player')

# Initialize variables to store total adverse correlation, regression coefficient, and player count
total_adverse_correlation = 0
total_regression_coefficient = 0
adverse_player_count = 0

# Calculate correlation and regression coefficient between Median_Age and Avg_EPM_After per player post peak age 29
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        # Consider only players above peak age (to focus on the adverse trend)
        adverse_impact_group = group[group['Median_Age'] > peak_age]

        # Check if the adverse_impact_group has at least one row
        if len(adverse_impact_group) == 0:
            continue  # Skip this group if it has no rows

        # Check if there's no variation in Median_Age or Avg_EPM_After
        if np.std(adverse_impact_group['Median_Age']) == 0 or np.std(adverse_impact_group['Avg_EPM_After']) == 0:
            continue  # Skip this group if there's no variation

        # Calculate the correlation
        correlation = adverse_impact_group['Median_Age'].corr(adverse_impact_group['Avg_EPM_After'])

        # Calculate the regression coefficient (slope)
        X = adverse_impact_group[['Median_Age']].values.reshape(-1, 1)
        y = adverse_impact_group['Avg_EPM_After'].values

        if len(X) > 1 and len(y) > 1:  # Ensure there are enough samples for regression
            reg = LinearRegression().fit(X, y)
            regression_coefficient = reg.coef_[0]  # Get the slope of the regression line

            if pd.notna(correlation):  # Check if correlation is not NaN
                total_adverse_correlation += correlation
                total_regression_coefficient += regression_coefficient
                adverse_player_count += 1

# Calculate the average adverse correlation and regression coefficient
if adverse_player_count > 0:
    average_adverse_correlation = total_adverse_correlation / adverse_player_count
    average_regression_coefficient = total_regression_coefficient / adverse_player_count
else:
    average_adverse_correlation = None  # In case there were no valid correlations
    average_regression_coefficient = None  # In case there were no valid regression coefficients

# Print the average adverse correlation and regression coefficient
print(f"Average correlation between Median_Age and Avg_EPM_After post peak age 29: {average_adverse_correlation:.4f}")
print(f"Average regression coefficient for Median_Age on Avg_EPM_After post peak age 29: {average_regression_coefficient:.4f}\n")
print(f'For every increase in Median_Age by one (post age 29), we expect Avg_EPM_After to decrease by {average_regression_coefficient:.4f} units')

"""### EW"""

# DETERMINING THE IMPACT OF AGE ON EW PERFORMANCE, PER PLAYER (i.e. AGE CURVES PER PLAYER)

# Group data by player
player_age_groups = age_df.groupby('Player')

# Initialize variables to store total correlation and player count
total_correlation = 0
player_count = 0

# Calculate correlation between Median_Age and Avg_EW_After per player
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        # Check if there's no variation in Median_Age or Avg_EW_After
        if np.std(group['Median_Age']) == 0 or np.std(group['Avg_EW_After']) == 0:
            continue  # Skip this group if there's no variation
        correlation = group['Median_Age'].corr(group['Avg_EW_After'])
        if pd.notna(correlation):  # Check if correlation is not NaN
            total_correlation += correlation
            player_count += 1

# Calculate the average correlation
if player_count > 0:
    average_correlation = total_correlation / player_count
else:
    average_correlation = None  # In case there were no valid correlations

# Print the average correlation = TRUE AVG. IMPACT OF AGE ON EW PERFORMANCE
print(f"Average correlation between Median_Age and Avg_EW_After: {average_correlation:.4f}")

# AGE CURVE GRAPHS (Median_Age vs. Avg_EW_After)

import plotly.graph_objects as go
from scipy.optimize import curve_fit

# Function to fit a quadratic curve
def quadratic_fit(x, a, b, c):
    return a * x**2 + b * x + c

# Create the plot
fig = go.Figure()

all_ages = []
all_ews = []

# Iterate through all qualified players
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        ages = group['Median_Age']
        ews = group['Avg_EW_After']

        # Add individual player curve
        fig.add_trace(go.Scatter(x=ages, y=ews, mode='markers+lines', name=player,
                                 line=dict(color='lightblue', width=1),
                                 marker=dict(color='lightblue', size=4),
                                 opacity=0.3, showlegend=False))

        all_ages.extend(ages)
        all_ews.extend(ews)

# Fit a quadratic curve to all data points
all_ages = np.array(all_ages)
all_ews = np.array(all_ews)
popt, _ = curve_fit(quadratic_fit, all_ages, all_ews)

# Generate points for the fitted curve
x_fit = np.linspace(min(all_ages), max(all_ages), 100)
y_fit = quadratic_fit(x_fit, *popt)

# Add the fitted curve
fig.add_trace(go.Scatter(x=x_fit, y=y_fit, mode='lines', name='Quadratic Fit',
                         line=dict(color='red', width=3)))

# Update layout
fig.update_layout(title='Age Curves for All Qualified Players',
                  xaxis_title='Median Age',
                  yaxis_title='Avg EW After',
                  showlegend=True)

# Show the plot
fig.show()

# Print the quadratic fit parameters
print(f"Quadratic fit: y = {popt[0]:.4f}x^2 + {popt[1]:.4f}x + {popt[2]:.4f}")

# Calculate the age of peak performance
peak_age = -popt[1] / (2 * popt[0])
print(f"Estimated age of peak EW performance: {peak_age:.2f}")

# Create a long-format dataset
Peak_Age_EW = NBA_FVC_initial_filter.copy()

long_df = pd.melt(Peak_Age_EW,
                  id_vars=['Player', 'Age_At_Start'],
                  value_vars=['EW_2Y_Before', 'EW_1Y_Before', 'EW_1Y_After', 'EW_2Y_After', 'EW_3Y_After', 'EW_4Y_After', 'EW_5Y_After'],
                  var_name='Season',
                  value_name='EW')

def calculate_age(row):
    age_at_start = row['Age_At_Start']
    season = row['Season']
    if season == 'EW_2Y_Before':
        return age_at_start - 2
    elif season == 'EW_1Y_Before':
        return age_at_start - 1
    elif season == 'EW_1Y_After':
        return age_at_start
    elif season == 'EW_2Y_After':
        return age_at_start + 1
    elif season == 'EW_3Y_After':
        return age_at_start + 2
    elif season == 'EW_4Y_After':
        return age_at_start + 3
    elif season == 'EW_5Y_After':
        return age_at_start + 4
    else:
        return age_at_start

long_df['Age'] = long_df.apply(calculate_age, axis=1)

# Group by Age and calculate average EW
avg_epm_by_age = long_df.groupby('Age')['EW'].mean().reset_index()

# Create the Plotly bar graph
fig = px.bar(avg_epm_by_age, x='Age', y='EW', title='Average EW by Age')
fig.update_layout(xaxis_title='Age', yaxis_title='Average EW')

# Show the plot
fig.show()

# DETERMINING THE ADVERSE IMPACT OF AGE ON EW PERFORMANCE, PER PLAYER, POST PEAK AGE 29

# Define the peak age
peak_age = 29

# Group data by player
player_age_groups = age_df.groupby('Player')

# Initialize variables to store total adverse correlation, regression coefficient, and player count
total_adverse_correlation = 0
total_regression_coefficient = 0
adverse_player_count = 0

# Calculate correlation and regression coefficient between Median_Age and Avg_EW_After per player post peak age 29
for player, group in player_age_groups:
    if len(group) > 1:  # Only consider players with multiple entries
        # Consider only players above peak age (to focus on the adverse trend)
        adverse_impact_group = group[group['Median_Age'] > peak_age]

        # Check if the adverse_impact_group has at least one row
        if len(adverse_impact_group) == 0:
            continue  # Skip this group if it has no rows

        # Check if there's no variation in Median_Age or Avg_EW_After
        if np.std(adverse_impact_group['Median_Age']) == 0 or np.std(adverse_impact_group['Avg_EW_After']) == 0:
            continue  # Skip this group if there's no variation

        # Calculate the correlation
        correlation = adverse_impact_group['Median_Age'].corr(adverse_impact_group['Avg_EW_After'])

        # Calculate the regression coefficient (slope)
        X = adverse_impact_group[['Median_Age']].values.reshape(-1, 1)
        y = adverse_impact_group['Avg_EW_After'].values

        if len(X) > 1 and len(y) > 1:  # Ensure there are enough samples for regression
            reg = LinearRegression().fit(X, y)
            regression_coefficient = reg.coef_[0]  # Get the slope of the regression line

            if pd.notna(correlation):  # Check if correlation is not NaN
                total_adverse_correlation += correlation
                total_regression_coefficient += regression_coefficient
                adverse_player_count += 1

# Calculate the average adverse correlation and regression coefficient
if adverse_player_count > 0:
    average_adverse_correlation = total_adverse_correlation / adverse_player_count
    average_regression_coefficient = total_regression_coefficient / adverse_player_count
else:
    average_adverse_correlation = None  # In case there were no valid correlations
    average_regression_coefficient = None  # In case there were no valid regression coefficients

# Print the average adverse correlation and regression coefficient
print(f"Average correlation between Median_Age and Avg_EW_After post peak age 29: {average_adverse_correlation:.4f}")
print(f"Average regression coefficient for Median_Age on Avg_EW_After post peak age 29: {average_regression_coefficient:.4f}\n")
print(f'For every increase in Median_Age by one (post age 29), we expect Avg_EW_After to decrease by {average_regression_coefficient:.4f} units')

"""## Visualizations"""

NBA_FVC_filtered.columns

# NEW AGE COLUMNS CORRELATION MATRIX

# Specify columns for correlation
age_columns = [
    'Age_At_Start', 'Median_Age', 'Peak_Age_Range', 'Far_From_Peak',
    'Avg_EPM_After', 'Avg_EW_After', 'AAV / Salary Cap'
]

# Calculate correlation matrix
correlation_matrix = NBA_FVC_filtered[age_columns].corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".3f", linewidths=0.5)
plt.title('Age Correlation Matrix')
plt.show()

# Specify columns for correlation
production_columns = [
    'Role', 'W_Avg_GP_Before', 'W_Avg_MPG_Before', 'W_Avg_Min_Before', 'W_Avg_USG_Before',
    'Avg_EPM_Before', 'W_Avg_EPM_Before', 'Age_Adj_EPM_Before', 'Avg_EPM_After',
    'Avg_EW_Before', 'W_Avg_EW_Before', 'Age_Adj_EW_Before', 'Avg_EW_After'
]

# Calculate correlation matrix
correlation_matrix = NBA_FVC_filtered[production_columns].corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".3f", linewidths=0.5)
plt.title('EPM/EW Correlation Matrix')
plt.show()

# # Specify columns for correlation
# new_ft_columns = [
#     'Median_Age', 'Avg_GP_Before', 'W_Avg_GP_Before', 'Avg_MPG_Before', 'W_Avg_MPG_Before', 'W_Avg_Min_Before', 'Avg_USG_Before', 'W_Avg_USG_Before',
#     'W_Avg_EPM_Before', 'Age Adj. EPM Before', 'Avg_EPM_After', 'W_Avg_EW_Before', 'Age Adj. EW Before', 'Avg_EW_After', 'AAV / Salary Cap',
# ]

# # Calculate correlation matrix
# correlation_matrix = NBA_FVC_filtered[new_ft_columns].corr()

# # Plot heatmap
# plt.figure(figsize=(12, 8))
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".3f", linewidths=0.5)
# plt.title('GP / MPG / USG Correlation Matrix')
# plt.show()

# Specify columns for correlation
contract_columns = [
    'Role', 'Median_Age', 'Far_From_Peak',
    'W_Avg_MPG_Before', 'W_Avg_USG_Before',
    'W_Avg_EPM_Before', 'Age_Adj_EPM_Before', 'Avg_EPM_After',
    'W_Avg_EW_Before', 'Age_Adj_EW_Before', 'Avg_EW_After',
    'AAV / Salary Cap', 'AAV / 2nd Apron'
]

# Calculate correlation matrix
correlation_matrix = NBA_FVC_filtered[contract_columns].corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".3f", linewidths=0.5)
plt.title('Contract Correlation Matrix')
plt.show()

# Summary Statistics for Key Variables ".describe()"

summary_stats = NBA_FVC_filtered[contract_columns].describe()
summary_stats

# Create scatter plot for 'Age_At_Start' vs 'Avg_EPM_After'
fig_age_signing = px.scatter(
    NBA_FVC_filtered,
    x='Age_At_Start',
    y='Avg_EPM_After',
    hover_name='Player',  # Hover will show player name
    hover_data={'Age_At_Start': True, 'Avg_EPM_After': True},  # Hover to show these fields
    title='Age At Start vs Average EPM After',
    trendline='ols'  # linear trendline (Ordinary Least Squares)
)

fig_age_signing.show()

# Create scatter plot for 'Median Age' vs 'Avg_EPM_After'
fig_median_age = px.scatter(
    NBA_FVC_filtered,
    x='Median_Age',
    y='Avg_EPM_After',
    hover_name='Player',  # Hover will show player name
    hover_data={'Median_Age': True, 'Avg_EPM_After': True},  # Hover to show these fields
    title='Median Age vs Average EPM After',
    trendline='ols'  # linear trendline (Ordinary Least Squares)
)

fig_median_age.show()

# Create scatter plot for 'Far_From_Peak' vs 'Avg_EPM_After'
fig_distance_peak = px.scatter(
    NBA_FVC_filtered,
    x='Far_From_Peak',
    y='Avg_EPM_After',
    hover_name='Player',  # Hover will show player name
    hover_data={'Far_From_Peak': True, 'Avg_EPM_After': True},  # Hover to show these fields
    title='Distance From Peak vs Average EPM After',
    trendline='ols'  # linear trendline (Ordinary Least Squares)
)

fig_distance_peak.show()

# # List of column pairs you want to compare
# column_pairs = [('W_Avg_EPM_Before', 'EPM_1Y_After'),
#                 ('W_Avg_EW_Before', 'EW_1Y_After'),
#                 ('Age At Signing', 'AAV'),
#                 ('AAV', 'Start'),
#                 ('AAV / Salary Cap','EPM_1Y_After')]  # Replace with actual column names

# # Create scatter plots for the specified column pairs
# for col1, col2 in column_pairs:
#     plt.figure()
#     plt.scatter(NBA_FVC_filtered[col1], NBA_FVC_filtered[col2])
#     plt.xlabel(col1)
#     plt.ylabel(col2)
#     plt.title(f'Scatter plot of {col1} vs. {col2}')
#     plt.show()

contract_changes = NBA_FVC_initial_filter.copy()

# Group by 'Start' year and calculate the average 'AAV / Salary Cap'
avg_aav_by_year = contract_changes.groupby('Start')['AAV / Salary Cap'].mean().reset_index()

# Create the Plotly bar graph
fig = px.bar(avg_aav_by_year,
             x='Start',
             y='AAV / Salary Cap',
             title='Average AAV / Salary Cap by Year',
             labels={'Start': 'Year', 'AAV / Salary Cap': 'Avg. AAV / Salary Cap'},
             text='AAV / Salary Cap')

# Customize the layout
fig.update_traces(texttemplate='%{text:.2%}', textposition='outside')
fig.update_layout(
    xaxis_title='Year',
    yaxis_title='Average AAV / Salary Cap',
    yaxis_tickformat='.2%',
    xaxis=dict(tickmode='linear', dtick=1)  # Ensure all years are shown on x-axis
)

# Show the plot
fig.show()

# Find the year with the highest average AAV / Salary Cap
max_year = avg_aav_by_year.loc[avg_aav_by_year['AAV / Salary Cap'].idxmax(), 'Start']
max_value = avg_aav_by_year['AAV / Salary Cap'].max()

print(f"Year with highest Avg. AAV / Salary Cap: {max_year} ({max_value:.2%})")

# Calculate year-over-year changes
avg_aav_by_year['YoY_Change'] = avg_aav_by_year['AAV / Salary Cap'].pct_change()

print("\nYear-over-Year Changes:")
print(avg_aav_by_year[['Start', 'YoY_Change']].to_string(index=False))

"""# EPM & EW Models

## EPM
"""

from sklearn.model_selection import train_test_split

# 80/20 TRAIN/TEST SPLIT
NBA_FVC_training_set, NBA_FVC_test_set = train_test_split(NBA_FVC_filtered, test_size=0.2, random_state=42)

# Check the sizes of each set
print(f"Training set size: {len(NBA_FVC_training_set)}")
print(f"Test set size: {len(NBA_FVC_test_set)}\n")

# NBA_FVC_training_set = NBA_FVC_filtered[(NBA_FVC_filtered['Start'] >= 2014) & (NBA_FVC_filtered['Start'] <= 2022)]
# NBA_FVC_test_set = NBA_FVC_filtered[NBA_FVC_filtered['Start'] == 2023].copy()

# FILTER FOR 2024/25 DATA (DEPLOYMENT SET)
NBA_FVC_2024 = NBA_FVC_initial_filter[NBA_FVC_initial_filter['Start'] == 2024]

# BASELINE MODELS
from sklearn.metrics import mean_squared_error
NBA_FVC_mean_epm = NBA_FVC_filtered['Avg_EPM_After'].mean()
NBA_FVC_test_set['Predicted_Avg_EPM'] = NBA_FVC_mean_epm
NBA_FVC_baseline_rmse = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['Predicted_Avg_EPM']))
print("Baseline RMSE:", NBA_FVC_baseline_rmse.round(4), "Mean:", NBA_FVC_mean_epm.round(4))

## Checking for NaN predictor values
# NBA_FVC_training_set[['Player', 'Role', 'Age At Signing', 'W_Avg_Min_Before', 'W_Avg_USG_Before', 'W_Avg_EPM_Before', 'Avg_EPM_After']]

# PRE-PROCESS (NORMALIZE) PREDICTOR DATA INTO Z-SCORES

from sklearn.preprocessing import StandardScaler

# Define numerical predictors (excluding the binary variable 'Peak_Age_Range' from standardization)
# numerical_predictors = ['Far_From_Peak', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before']
numerical_predictors = ['W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before']

# Standardize only the numerical predictors
scaler = StandardScaler()

NBA_FVC_training_set[numerical_predictors] = scaler.fit_transform(NBA_FVC_training_set[numerical_predictors])
NBA_FVC_test_set[numerical_predictors] = scaler.transform(NBA_FVC_test_set[numerical_predictors])

NBA_FVC_2024[numerical_predictors] = scaler.transform(NBA_FVC_2024[numerical_predictors])

# Include 'Peak_Age_Range' in the full set of predictors
NBA_FVC_EPM_predictors = numerical_predictors + ['Peak_Age_Range']
# NBA_FVC_EPM_predictors = numerical_predictors

"""### Individual Models"""

# LASSO EPM MODEL

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error

NBA_FVC_EPM_target = 'Avg_EPM_After'

# Create and train the Lasso model (increase alpha to encourage feature selection)
alpha_value = 0.1
NBA_FVC_EPM_lasso_model = Lasso(alpha=alpha_value)
NBA_FVC_EPM_lasso_model.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])

# Make predictions on the test set
NBA_FVC_test_set['Lasso_Predicted_Avg_EPM'] = NBA_FVC_EPM_lasso_model.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

# # Adjust predictions for players older than 29
# age_adjustment_factor = -0.7612  # The discovered coefficient
# NBA_FVC_test_set['Age_Adjustment'] = NBA_FVC_test_set.apply(
#     lambda row: 0.05 * (age_adjustment_factor * (row['Median_Age'] - 29)) if row['Median_Age'] > 29 else 0, axis=1) # modify multiplier as needed

# NBA_FVC_test_set['Lasso_Predicted_Avg_EPM'] = NBA_FVC_test_set['Lasso_Predicted_Avg_EPM'] + NBA_FVC_test_set['Age_Adjustment']

# Calculate RMSE and R-squared
NBA_FVC_EPM_rmse_lasso = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['Lasso_Predicted_Avg_EPM']))
print("Lasso RMSE:", round(NBA_FVC_EPM_rmse_lasso, 4))

NBA_FVC_EPM_r2_lasso = NBA_FVC_EPM_lasso_model.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("Lasso R-squared:", round(NBA_FVC_EPM_r2_lasso, 4))

# Get the coefficients and identify which predictors are kept
lasso_coefficients = pd.Series(NBA_FVC_EPM_lasso_model.coef_, index=NBA_FVC_EPM_predictors)
print()
print("Lasso Coefficients:")
print(lasso_coefficients)

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['Lasso_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'Far_From_Peak', 'Peak_Age_Range', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'Lasso_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# RIDGE EPM MODEL

from sklearn.linear_model import Ridge

# Create and train the Ridge model (alpha controls regularization strength)
alpha_value = 0.1
NBA_FVC_EPM_ridge_model = Ridge(alpha=alpha_value)
NBA_FVC_EPM_ridge_model.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])

# Make predictions on the test set
NBA_FVC_test_set['Ridge_Predicted_Avg_EPM'] = NBA_FVC_EPM_ridge_model.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

# Calculate RMSE and R-squared
NBA_FVC_EPM_rmse_ridge = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['Ridge_Predicted_Avg_EPM']))
print("Ridge RMSE:", round(NBA_FVC_EPM_rmse_ridge, 4))

NBA_FVC_EPM_r2_ridge = NBA_FVC_EPM_ridge_model.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("Ridge R-squared:", round(NBA_FVC_EPM_r2_ridge, 4))

# Get the coefficients and display them
ridge_coefficients = pd.Series(NBA_FVC_EPM_ridge_model.coef_, index=NBA_FVC_EPM_predictors)
print("Ridge Coefficients:")
print(ridge_coefficients)

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['Ridge_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'Ridge_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# RANDOM FOREST EPM MODEL

from sklearn.ensemble import RandomForestRegressor

# Initialize the Random Forest Regressor
NBA_FVC_EPM_rf_model = RandomForestRegressor(random_state=42, n_estimators=100)

# Fit the model to the training data
NBA_FVC_EPM_rf_model.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])

# Make predictions on the test set
NBA_FVC_test_set['RF_Predicted_Avg_EPM'] = NBA_FVC_EPM_rf_model.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

# RMSE & R^2
NBA_FVC_EPM_rmse_rf = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['RF_Predicted_Avg_EPM']))
print("RF RMSE:", round(NBA_FVC_EPM_rmse_rf, 4))

NBA_FVC_EPM_r2_rf = NBA_FVC_EPM_rf_model.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("RF R-squared:", round(NBA_FVC_EPM_r2_rf, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['RF_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display the relevant columns
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'RF_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# SIMPLE LINEAR EPM MODEL

from sklearn.linear_model import LinearRegression

# Create and train the linear model
NBA_FVC_EPM_linear_model = LinearRegression()
NBA_FVC_EPM_linear_model.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])

# Make predictions on the test set
NBA_FVC_test_set['Linear_Predicted_Avg_EPM'] = NBA_FVC_EPM_linear_model.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

# Calculate RMSE and R-squared
NBA_FVC_EPM_rmse_lm = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['Linear_Predicted_Avg_EPM']))
print("LM RMSE:", round(NBA_FVC_EPM_rmse_lm, 4))

NBA_FVC_EPM_r2_lm = NBA_FVC_EPM_linear_model.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("LM R-squared:", round(NBA_FVC_EPM_r2_lm, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['Linear_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'Linear_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# K-NEAREST NEIGHBORS (kNN) EPM MODEL

from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import cross_val_score

# Initialize the kNN Regressor (you can set k using the 'n_neighbors' parameter)
NBA_FVC_EPM_knn_model = KNeighborsRegressor(n_neighbors=15) # k=5 by default
                                                            # "optimal k" code from before wasn't working correctly (likely showing optimal k on training set, rather than test set)
# Fit the model to the training data
NBA_FVC_EPM_knn_model.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])

# Make predictions on the test set
NBA_FVC_test_set['kNN_Predicted_Avg_EPM'] = NBA_FVC_EPM_knn_model.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

# RMSE & R^2
NBA_FVC_EPM_rmse_kNN = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['kNN_Predicted_Avg_EPM']))
print("kNN RMSE:", round(NBA_FVC_EPM_rmse_kNN, 4))

NBA_FVC_EPM_r2_kNN = NBA_FVC_EPM_knn_model.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("kNN R-squared:", round(NBA_FVC_EPM_r2_kNN, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['kNN_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display the relevant columns
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'kNN_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# GRADIENT BOOSTING EPM MODEL

from sklearn.ensemble import GradientBoostingRegressor

# Initialize the Gradient Boosting Regressor model
NBA_FVC_EPM_gbm = GradientBoostingRegressor()

NBA_FVC_EPM_gbm.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])

NBA_FVC_test_set['GB_Predicted_Avg_EPM'] = NBA_FVC_EPM_gbm.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

NBA_FVC_EPM_rmse_gbm = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['GB_Predicted_Avg_EPM']))
print("GB RMSE:", round(NBA_FVC_EPM_rmse_gbm, 4))

NBA_FVC_EPM_r2_gbm = NBA_FVC_EPM_gbm.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("GB R-squared:", round(NBA_FVC_EPM_r2_gbm, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['GB_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display relevant columns
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before',
                  'GB_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# XGBoost EPM MODEL

from xgboost import XGBRegressor

NBA_FVC_EPM_xgb = XGBRegressor()
NBA_FVC_EPM_xgb.fit(NBA_FVC_training_set[NBA_FVC_EPM_predictors], NBA_FVC_training_set[NBA_FVC_EPM_target])
NBA_FVC_test_set['XGB_Predicted_Avg_EPM'] = NBA_FVC_EPM_xgb.predict(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

NBA_FVC_EPM_rmse_xgb = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['XGB_Predicted_Avg_EPM']))
print("XGB RMSE:", round(NBA_FVC_EPM_rmse_xgb, 4))

NBA_FVC_EPM_r2_xgb = NBA_FVC_EPM_xgb.score(NBA_FVC_test_set[NBA_FVC_EPM_predictors], NBA_FVC_test_set[NBA_FVC_EPM_target])
print("XGB R-squared:", round(NBA_FVC_EPM_r2_xgb, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['XGB_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display relevant columns
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before',
                  'XGB_Predicted_Avg_EPM', 'Avg_EPM_After', 'Residual']]

# # NEURAL NETWORK EPM MODEL

# from sklearn.metrics import r2_score
# from sklearn.preprocessing import StandardScaler
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense

# # Define predictors and target
# NBA_FVC_EPM_predictors = ['Role', 'Median Age', 'W_Avg_Min_Before', 'W_Avg_USG_Before', 'Age Adj. EPM Before']
# NBA_FVC_EPM_target = 'Avg_EPM_After'

# # Standardize the data (important for neural networks)
# scaler = StandardScaler()
# NBA_FVC_training_scaled = scaler.fit_transform(NBA_FVC_training_set[NBA_FVC_EPM_predictors])
# NBA_FVC_test_scaled = scaler.transform(NBA_FVC_test_set[NBA_FVC_EPM_predictors])

# # Define the neural network model
# model = Sequential()

# # Add layers to the model (input layer + 2 hidden layers + output layer)
# model.add(Dense(64, input_dim=len(NBA_FVC_EPM_predictors), activation='relu'))  # Input layer and 1st hidden layer
# model.add(Dense(32, activation='relu'))  # 2nd hidden layer
# model.add(Dense(1, activation='linear'))  # Output layer (linear activation for regression)

# # Compile the model
# model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])

# # Train the model
# model.fit(NBA_FVC_training_scaled, NBA_FVC_training_set[NBA_FVC_EPM_target], epochs=100, batch_size=32, verbose=1)

# # Make predictions on the test set
# NBA_FVC_test_set['NN_Predicted_Avg_EPM'] = model.predict(NBA_FVC_test_scaled)

# # Calculate RMSE and R-squared
# NBA_FVC_EPM_rmse_nn = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['NN_Predicted_Avg_EPM']))
# NBA_FVC_EPM_r2_nn = r2_score(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['NN_Predicted_Avg_EPM'])

# print("NN RMSE:", round(NBA_FVC_EPM_rmse_nn, 4))
# print("NN R-squared:", round(NBA_FVC_EPM_r2_nn, 4))

# # Add a residual column to the test set (Residual = Predicted - Actual)
# NBA_FVC_test_set['NN_Residual'] = NBA_FVC_test_set['NN_Predicted_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# # Display the selected columns with residuals
# NBA_FVC_test_set[['Player', 'Role', 'Median Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'NN_Predicted_Avg_EPM', 'Avg_EPM_After', 'NN_Residual']]

"""### Ensemble"""

# ENSEMBLE EPM MODEL

from sklearn.metrics import r2_score

NBA_FVC_test_set['Ensemble_Pred_Avg_EPM'] = (NBA_FVC_test_set['Lasso_Predicted_Avg_EPM'] +
                                             NBA_FVC_test_set['Linear_Predicted_Avg_EPM'] +
                                             NBA_FVC_test_set['kNN_Predicted_Avg_EPM']) / 3  # Dividing by the total number of models

# Calculate RMSE and R-squared
NBA_FVC_EPM_rmse_ensemble = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['Ensemble_Pred_Avg_EPM']))
print("Ensemble RMSE:", round(NBA_FVC_EPM_rmse_ensemble, 4))

NBA_FVC_EPM_r2_ensemble = r2_score(NBA_FVC_test_set['Avg_EPM_After'], NBA_FVC_test_set['Ensemble_Pred_Avg_EPM'])
print("Ensemble R-squared:", round(NBA_FVC_EPM_r2_ensemble, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['EPM_Residual'] = NBA_FVC_test_set['Ensemble_Pred_Avg_EPM'] - NBA_FVC_test_set['Avg_EPM_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'Ensemble_Pred_Avg_EPM', 'Avg_EPM_After', 'EPM_Residual']]

"""## EW"""

# BASELINE MODELS

NBA_FVC_mean_ew = NBA_FVC_filtered['Avg_EW_After'].mean()
NBA_FVC_test_set['Predicted_Avg_EW'] = NBA_FVC_mean_ew
NBA_FVC_baseline_rmse = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['Predicted_Avg_EW']))
print("Baseline RMSE:", NBA_FVC_baseline_rmse.round(4), "Mean:", NBA_FVC_mean_ew.round(4))

# DEFINE PREDICTORS FOR EW MODELS

scaler = StandardScaler()

# Standardize 'Age_Adj_EW_Before' & 'W_Avg_Min_Before'
NBA_FVC_training_set['Age_Adj_EW_Before'] = scaler.fit_transform(NBA_FVC_training_set[['Age_Adj_EW_Before']])
NBA_FVC_test_set['Age_Adj_EW_Before'] = scaler.transform(NBA_FVC_test_set[['Age_Adj_EW_Before']])

NBA_FVC_2024['Age_Adj_EW_Before'] = scaler.transform(NBA_FVC_2024[['Age_Adj_EW_Before']])

# NBA_FVC_training_set['W_Avg_Min_Before'] = scaler.fit_transform(NBA_FVC_training_set[['W_Avg_Min_Before']])
# NBA_FVC_test_set['W_Avg_Min_Before'] = scaler.transform(NBA_FVC_test_set[['W_Avg_Min_Before']])

# Define the EW predictors
# NBA_FVC_EW_predictors = ['Peak_Age_Range', 'Far_From_Peak', 'W_Avg_Min_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before']
NBA_FVC_EW_predictors = ['W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before']

"""### Individual Models"""

# LASSO EW MODEL

NBA_FVC_EW_target = 'Avg_EW_After'

# Create and train the Lasso model (increase alpha to encourage feature selection)
alpha_value = 0.1
NBA_FVC_EW_lasso_model = Lasso(alpha=alpha_value)
NBA_FVC_EW_lasso_model.fit(NBA_FVC_training_set[NBA_FVC_EW_predictors], NBA_FVC_training_set[NBA_FVC_EW_target])

# Make predictions on the test set
NBA_FVC_test_set['Lasso_Predicted_Avg_EW'] = NBA_FVC_EW_lasso_model.predict(NBA_FVC_test_set[NBA_FVC_EW_predictors])

# # Adjust predictions for players older than 29
# age_adjustment_factor = -0.7738  # The discovered coefficient
# NBA_FVC_test_set['Age_Adjustment'] = NBA_FVC_test_set.apply(
#     lambda row: 0.05 * (age_adjustment_factor * (row['Median_Age'] - 29)) if row['Median_Age'] > 29 else 0, axis=1) # modify multiplier as needed

# NBA_FVC_test_set['Lasso_Predicted_Avg_EW'] = NBA_FVC_test_set['Lasso_Predicted_Avg_EW'] + NBA_FVC_test_set['Age_Adjustment']

# Calculate RMSE and R-squared
NBA_FVC_EW_rmse_lasso = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['Lasso_Predicted_Avg_EW']))
print("Lasso RMSE:", round(NBA_FVC_EW_rmse_lasso, 4))

NBA_FVC_EW_r2_lasso = NBA_FVC_EW_lasso_model.score(NBA_FVC_test_set[NBA_FVC_EW_predictors], NBA_FVC_test_set[NBA_FVC_EW_target])
print("Lasso R-squared:", round(NBA_FVC_EW_r2_lasso, 4))

# Get the coefficients and identify which predictors are kept
lasso_coefficients = pd.Series(NBA_FVC_EW_lasso_model.coef_, index=NBA_FVC_EW_predictors)
print()
print("Lasso Coefficients:")
print(lasso_coefficients)

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['Lasso_Predicted_Avg_EW'] - NBA_FVC_test_set['Avg_EW_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'Far_From_Peak', 'Peak_Age_Range', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before', 'Lasso_Predicted_Avg_EW', 'Avg_EW_After', 'Residual']]

# RIDGE EW MODEL

# Create and train the Ridge model (alpha controls regularization strength)
alpha_value = 1.0
NBA_FVC_EW_ridge_model = Ridge(alpha=alpha_value)
NBA_FVC_EW_ridge_model.fit(NBA_FVC_training_set[NBA_FVC_EW_predictors], NBA_FVC_training_set[NBA_FVC_EW_target])

# Make predictions on the test set
NBA_FVC_test_set['Ridge_Predicted_Avg_EW'] = NBA_FVC_EW_ridge_model.predict(NBA_FVC_test_set[NBA_FVC_EW_predictors])

# Calculate RMSE and R-squared
NBA_FVC_EW_rmse_ridge = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['Ridge_Predicted_Avg_EW']))
print("Ridge RMSE:", round(NBA_FVC_EW_rmse_ridge, 4))

NBA_FVC_EW_r2_ridge = NBA_FVC_EW_ridge_model.score(NBA_FVC_test_set[NBA_FVC_EW_predictors], NBA_FVC_test_set[NBA_FVC_EW_target])
print("Ridge R-squared:", round(NBA_FVC_EW_r2_ridge, 4))

# Get the coefficients and display them
ridge_coefficients = pd.Series(NBA_FVC_EW_ridge_model.coef_, index=NBA_FVC_EW_predictors)
print("Ridge Coefficients:")
print(ridge_coefficients)

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['Ridge_Predicted_Avg_EW'] - NBA_FVC_test_set['Avg_EW_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Start', 'Peak_Age_Range', 'Far_From_Peak', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before', 'Ridge_Predicted_Avg_EW', 'Avg_EW_After', 'Residual']]

# SIMPLE LINEAR EW MODEL

NBA_FVC_EW_linear_model = LinearRegression()
NBA_FVC_EW_linear_model.fit(NBA_FVC_training_set[NBA_FVC_EW_predictors], NBA_FVC_training_set[NBA_FVC_EW_target])
NBA_FVC_test_set['Linear_Predicted_Avg_EW'] = NBA_FVC_EW_linear_model.predict(NBA_FVC_test_set[NBA_FVC_EW_predictors])

NBA_FVC_EW_rmse_lm = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['Linear_Predicted_Avg_EW']))
print("LM RMSE:", round(NBA_FVC_EW_rmse_lm, 4))

NBA_FVC_EW_r2_lm = NBA_FVC_EW_linear_model.score(NBA_FVC_test_set[NBA_FVC_EW_predictors], NBA_FVC_test_set[NBA_FVC_EW_target])
print("LM R-squared:", round(NBA_FVC_EW_r2_lm, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['Linear_Predicted_Avg_EW'] - NBA_FVC_test_set['Avg_EW_After']

NBA_FVC_test_set[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before', 'Linear_Predicted_Avg_EW', 'Avg_EW_After', 'Residual']]

# RANDOM FOREST EW MODEL

# Initialize the Random Forest Regressor
NBA_FVC_EW_rf_model = RandomForestRegressor(random_state=42, n_estimators=100)

# Fit the model to the training data
NBA_FVC_EW_rf_model.fit(NBA_FVC_training_set[NBA_FVC_EW_predictors], NBA_FVC_training_set[NBA_FVC_EW_target])

# Make predictions on the test set
NBA_FVC_test_set['RF_Predicted_Avg_EW'] = NBA_FVC_EW_rf_model.predict(NBA_FVC_test_set[NBA_FVC_EW_predictors])

# RMSE & R^2
NBA_FVC_EW_rmse_rf = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['RF_Predicted_Avg_EW']))
print("RF RMSE:", round(NBA_FVC_EW_rmse_rf, 4))

NBA_FVC_EW_r2_rf = NBA_FVC_EW_rf_model.score(NBA_FVC_test_set[NBA_FVC_EW_predictors], NBA_FVC_test_set[NBA_FVC_EW_target])
print("RF R-squared:", round(NBA_FVC_EW_r2_rf, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['RF_Predicted_Avg_EW'] - NBA_FVC_test_set['Avg_EW_After']

# Display the relevant columns
NBA_FVC_test_set[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before', 'RF_Predicted_Avg_EW', 'Avg_EW_After', 'Residual']]

# K-NEAREST NEIGHBORS (kNN) EW MODEL

# Initialize the kNN Regressor (you can set k using the 'n_neighbors' parameter)
NBA_FVC_EW_knn_model = KNeighborsRegressor(n_neighbors=15) # k=5 by default
                                                            # "optimal k" code from before wasn't working correctly (likely showing optimal k on training set, rather than test set)
# Fit the model to the training data
NBA_FVC_EW_knn_model.fit(NBA_FVC_training_set[NBA_FVC_EW_predictors], NBA_FVC_training_set[NBA_FVC_EW_target])

# Make predictions on the test set
NBA_FVC_test_set['kNN_Predicted_Avg_EW'] = NBA_FVC_EW_knn_model.predict(NBA_FVC_test_set[NBA_FVC_EW_predictors])

# RMSE & R^2
NBA_FVC_EW_rmse_kNN = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['kNN_Predicted_Avg_EW']))
print("kNN RMSE:", round(NBA_FVC_EW_rmse_kNN, 4))

NBA_FVC_EW_r2_kNN = NBA_FVC_EW_knn_model.score(NBA_FVC_test_set[NBA_FVC_EW_predictors], NBA_FVC_test_set[NBA_FVC_EW_target])
print("kNN R-squared:", round(NBA_FVC_EW_r2_kNN, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['Residual'] = NBA_FVC_test_set['kNN_Predicted_Avg_EW'] - NBA_FVC_test_set['Avg_EW_After']

# Display the relevant columns
NBA_FVC_test_set[['Player', 'Role', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before', 'kNN_Predicted_Avg_EW', 'Avg_EW_After', 'Residual']]

"""### Ensemble"""

# ENSEMBLE EW MODEL

NBA_FVC_test_set['Ensemble_Pred_Avg_EW'] = (NBA_FVC_test_set['Ridge_Predicted_Avg_EW'] +
                                            NBA_FVC_test_set['RF_Predicted_Avg_EW'] +
                                            NBA_FVC_test_set['kNN_Predicted_Avg_EW']) / 3  # Dividing by the total number of models

# Calculate RMSE and R-squared
NBA_FVC_EW_rmse_ensemble = np.sqrt(mean_squared_error(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['Ensemble_Pred_Avg_EW']))
print("Ensemble RMSE:", round(NBA_FVC_EW_rmse_ensemble, 4))

NBA_FVC_EW_r2_ensemble = r2_score(NBA_FVC_test_set['Avg_EW_After'], NBA_FVC_test_set['Ensemble_Pred_Avg_EW'])
print("Ensemble R-squared:", round(NBA_FVC_EW_r2_ensemble, 4))

# Add a residual column to the test set (Residual = Predicted - Actual)
NBA_FVC_test_set['EW_Residual'] = NBA_FVC_test_set['Ensemble_Pred_Avg_EW'] - NBA_FVC_test_set['Avg_EW_After']

# Display the selected columns with residuals
NBA_FVC_test_set[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before', 'Ensemble_Pred_Avg_EW', 'Avg_EW_After', 'EW_Residual']]

"""# Fair Value Calculation

## 2024/25 Contracts
"""

NBA_FVC_2024.describe()

# PREDICT FUTURE EPM
## NBA_FVC_EPM_predictors = numerical_predictors + ['Peak_Age_Range']

NBA_FVC_2024['Lasso_Predicted_Avg_EPM'] = NBA_FVC_EPM_lasso_model.predict(NBA_FVC_2024[NBA_FVC_EPM_predictors])
NBA_FVC_2024['Linear_Predicted_Avg_EPM'] = NBA_FVC_EPM_linear_model.predict(NBA_FVC_2024[NBA_FVC_EPM_predictors])
NBA_FVC_2024['kNN_Predicted_Avg_EPM'] = NBA_FVC_EPM_knn_model.predict(NBA_FVC_2024[NBA_FVC_EPM_predictors])

NBA_FVC_2024['Ensemble_Pred_Avg_EPM'] = (NBA_FVC_2024['Lasso_Predicted_Avg_EPM'] +
                                          NBA_FVC_2024['Linear_Predicted_Avg_EPM'] +
                                          NBA_FVC_2024['kNN_Predicted_Avg_EPM']) / 3

# PREDICT FUTURE EW
## NBA_FVC_EW_predictors = ['W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EW_Before']

NBA_FVC_2024['Ridge_Predicted_Avg_EW'] = NBA_FVC_EW_ridge_model.predict(NBA_FVC_2024[NBA_FVC_EW_predictors])
NBA_FVC_2024['RF_Predicted_Avg_EW'] = NBA_FVC_EW_rf_model.predict(NBA_FVC_2024[NBA_FVC_EW_predictors])
NBA_FVC_2024['kNN_Predicted_Avg_EW'] = NBA_FVC_EW_knn_model.predict(NBA_FVC_2024[NBA_FVC_EW_predictors])

NBA_FVC_2024['Ensemble_Pred_Avg_EW'] = (NBA_FVC_2024['Ridge_Predicted_Avg_EW'] +
                                         NBA_FVC_2024['RF_Predicted_Avg_EW'] +
                                         NBA_FVC_2024['kNN_Predicted_Avg_EW']) / 3

# DISPLAY
NBA_FVC_2024[['Player', 'Start', 'Median_Age', 'W_Avg_MPG_Before', 'W_Avg_USG_Before', 'Age_Adj_EPM_Before', 'Age_Adj_EW_Before', 'Ensemble_Pred_Avg_EPM', 'Ensemble_Pred_Avg_EW']]

# EQUATE PREDICTED EPM/EW TO EXPECTED AAV (first as proportion of salary cap + maybe 2nd apron, then as $ amount)

"""## Past Contracts"""

# FOR PAST CONTRACTS (almost every player in dataset)
## predict EPM & EW After; equate to expected value; compare vs real value (largest residuals) + determine which AAV's were least correlated with 'After' performance
### trained on only completed contracts, but apply predictions to all pre-24/25 entries (might not need predictions anyways)